# Data loader parameters
task_name: "imputation"
train_batch_size : 64
val_batch_size: 128
shuffle: True
num_workers: 5
pin_memory: True
scale : True 
train_ratio : 0.7
val_ratio : 0.1
test_ratio : 0.2
random_seed : 13
upsampling_pad_direction : "backward"
upsampling_type : "pad" # pad by default
downsampling_type : "interpolate"
pad_mode : "edge" # constant by default
pad_constant_values : null

# Data parameters
output_type: 'multivariate' # 'multivariate' 

# Experiment parameters
use_amp: True
pct_start: 0.3
max_epoch: 5
anomaly_criterion: 'mse'
lr_scheduler_type: 'onecyclelr' 
finetuning_mode: "end-to-end" # "end-to-end"
debug: False
init_lr: 0.001 # 1e-3
loss_type: "mse"
log_interval: 1000
checkpoint_interval: 8000

# Model parameters
model_name: "GPT4TS"
forecast_horizon: 0
# Partly based on XXXX
gpt_layers: 3
patch_len: 1 # 1 in configs, 8 for MOMENT
patch_stride_len: 1 # 1 in configs, 8 for MOMENT 
seq_len: 512
randomly_initialize_backbone: False # Whether to randomly initialize the backbone
transformer_backbone: 'gpt2'
enable_gradient_checkpointing: True
freeze_transformer_backbone: True # By default freezes everything except the layer norms and the positional embeddings
d_ff: 768

    
    
    
    
    
    
    
    
    
    
    