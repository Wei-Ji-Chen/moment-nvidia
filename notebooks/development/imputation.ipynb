{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from moment.common import PATHS\n",
    "from moment.utils.config import Config\n",
    "from moment.utils.utils import parse_config\n",
    "from moment.utils.masking import Masking\n",
    "from moment.utils.forecasting_metrics import get_forecasting_metrics\n",
    "from moment.data.dataloader import get_timeseries_dataloader\n",
    "from moment.data.forecasting_datasets import get_forecasting_datasets\n",
    "from moment.models.base import BaseModel\n",
    "from moment.models.moment import MOMENT\n",
    "from moment.models.timesnet import TimesNet\n",
    "from moment.models.gpt4ts import GPT4TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES = [\n",
    "    \"Supervised finetuning on imputation datasets\", # MOMENT\n",
    "    \"Pre-training TimesNet for imputation\", # TimesNet\n",
    "    \"Pre-training GPT4TS for imputation\", # GPT4TS\n",
    "    ]\n",
    "\n",
    "runs_summary = pd.read_csv(\"../../assets/data/wandb_runs_summary.csv\")\n",
    "runs = runs_summary[runs_summary[\"notes\"].isin(NOTES)]\n",
    "runs = runs[['run_name', 'model_name', 'dataset_names', 'hostname']]\n",
    "\n",
    "runs.dataset_names = runs.dataset_names.apply(lambda x: x.split(\"/\")[-1][:-4])\n",
    "runs.hostname = runs.hostname.apply(lambda x: x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_map = {\n",
    "    \"MOMENTNTNTNT_LP\": \"../../configs/imputation/linear_probing.yaml\",\n",
    "    \"MOMENTNTNT_0\": \"../../configs/imputation/zero_shot.yaml\",\n",
    "    \"TimesNet\": \"../../configs/imputation/timesnet_train.yaml\",\n",
    "    \"GPT4TS\": \"../../configs/imputation/gpt4ts_train.yaml\",\n",
    "}\n",
    "\n",
    "def get_model(model_name, args):\n",
    "    if model_name == \"MOMENTNT_LP\" or model_name ==MOMENTMENT_0\":\n",
    "        model = MOMENTNT(args)\n",
    "    elif model_name == \"TimesNet\":\n",
    "        model = TimesNet(args)\n",
    "    elif model_name == \"GPT4TS\":\n",
    "        model = GPT4TS(args)\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not found.\")\n",
    "    return model\n",
    "\n",
    "def get_checkpoint_name(model_name):\n",
    "    if model_name == \"MOMENTNT_LP\" or model_name ==MOMENTMENT_0\":\n",
    "        return 'MOMENTNT.pth'\n",
    "    elif model_name == \"TimesNet\":\n",
    "        return 'TimesNet.pth'\n",
    "    elif model_name == \"GPT4TS\":\n",
    "        return 'GPT4TS.pth'\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not found.\")\n",
    "\n",
    "dataset_file_and_path_names = get_forecasting_datasets(collection='autoformer')\n",
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 0\n",
    "MASK_RATIOS = [0.125, 0.25, 0.375, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'ETTh1'\n",
    "MODEL_NAME = 'MOMENTNT_LP'\n",
    "\n",
    "dataset_name = [i for i in dataset_file_and_path_names if DATASET_NAME in i][0]\n",
    "\n",
    "config = Config(\n",
    "    config_file_path=config_file_map[MODEL_NAME], \n",
    "    default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "args = parse_config(config)\n",
    "\n",
    "args.full_file_path_and_name = dataset_name\n",
    "args.dataset_names = args.full_file_path_and_name\n",
    "args.data_split = 'test'\n",
    "args.output_type = 'multivariate'\n",
    "args.seq_len = 512\n",
    "args.shuffle = False\n",
    "args.data_stride_len = 512\n",
    "args.batch_size = 8 # args.val_batch_size\n",
    "# args.n_channels = 7 # 7 21 321\n",
    "\n",
    "test_dataloader = get_timeseries_dataloader(args=args)\n",
    "print(f\"Length of dataloader={len(test_dataloader)}, timeseries={len(test_dataloader.dataset.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load pre-trained MOMENTNT\n",
    "# run_name = \"fearless-planet-52\" \n",
    "# checkpoint = BaseModel.load_pretrained_weights(run_name=run_name, opt_steps=None)\n",
    "# config = Config(config_file_path=DEFAULT_CONFIG_PATH, default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "# config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# args = parse_config(config)\n",
    "# model = MOMENTNT(configs=args)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# model.eval()\n",
    "# model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs = runs.loc[(runs['model_name'] == MODEL_NAME.split('_')[0]) & (runs['dataset_names'] == DATASET_NAME)]\n",
    "if selected_runs.shape[0] > 1: \n",
    "    print(f\"More than one run found for the given source collection and frequency\\n{selected_runs}\")\n",
    "    selected_runs.loc[:, 'run_num'] = selected_runs.run_name.apply(lambda x: int(x.split(\"-\")[-1]))\n",
    "    selected_runs = selected_runs.sort_values(by=['run_num'], ascending=False)\n",
    "checkpoint_name = str(selected_runs.run_name.values[0])\n",
    "print(f\"Checkpoint name: {checkpoint_name}\")\n",
    "\n",
    "model = get_model(MODEL_NAME, args)\n",
    "\n",
    "with open(os.path.join(PATHS.CHECKPOINTS_DIR, f'{checkpoint_name}/{get_checkpoint_name(MODEL_NAME)}'), 'rb') as f:\n",
    "    checkpoint = torch.load(f, map_location='cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for mask_ratio in tqdm(MASK_RATIOS, total=len(MASK_RATIOS)):\n",
    "    \n",
    "    mask_generator = Masking(mask_ratio=mask_ratio) \n",
    "    masks, preds, trues = [], [], []\n",
    "    \n",
    "    for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        timeseries = batch.timeseries.float().to(args.device)\n",
    "        n_samples, n_channels, _ = timeseries.shape\n",
    "        input_mask = batch.input_mask.long().to(args.device)\n",
    "        mask = mask_generator.generate_mask(\n",
    "            x=timeseries, input_mask=input_mask).to(args.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.pretraining(\n",
    "                x_enc=timeseries, input_mask=input_mask)\n",
    "\n",
    "        masks.append(mask.repeat_interleave(n_channels, dim=0).detach().cpu().numpy())\n",
    "        trues.append(timeseries.detach().cpu().numpy())\n",
    "        preds.append(outputs.reconstruction.detach().cpu().numpy())\n",
    "\n",
    "    masks = np.concatenate(masks, axis=0).squeeze().flatten()\n",
    "    trues = np.concatenate(trues, axis=0).squeeze().flatten()\n",
    "    preds = np.concatenate(preds, axis=0).squeeze().flatten()\n",
    "\n",
    "    metrics = get_forecasting_metrics(\n",
    "                y=trues[masks==0], \n",
    "                y_hat=preds[masks==0], \n",
    "                reduction='mean')\n",
    "    \n",
    "    results.append([dataset_name.split('/')[-1][:-4], mask_ratio, metrics.mse, metrics.mae])\n",
    "results = pd.DataFrame(results, columns=['dataset', 'mask_ratio', 'MSE', 'MAE'])\n",
    "print(results)\n",
    "print(results.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import wandb\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from moment.common import PATHS\n",
    "\n",
    "\n",
    "def train(args, model, train_dataloader):\n",
    "        n_train_epochs = args.max_epoch\n",
    "        \n",
    "        # Training loop\n",
    "        tr_loss = 0\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), \n",
    "                                lr=args.init_lr,\n",
    "                                weight_decay=args.weight_decay)\n",
    "\n",
    "        criterion = nn.MSELoss() \n",
    "\n",
    "        logger = wandb.init(\n",
    "            project=\"Time-series Foundation Model\",\n",
    "            dir=PATHS.WANDB_DIR)\n",
    "        \n",
    "        for epoch in trange(n_train_epochs):\n",
    "            for batch in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "                timeseries = batch.timeseries.float().to(args.device)\n",
    "                input_mask = batch.input_mask.long().to(args.device)\n",
    "\n",
    "                model.train()\n",
    "                # Training step\n",
    "                outputs = model.pretraining(x_enc=timeseries, input_mask=input_mask)\n",
    "                \n",
    "                recon_loss = criterion(outputs.reconstruction, timeseries)\n",
    "                observed_mask = input_mask * (1 - outputs.pretrain_mask)\n",
    "                n_channels = outputs.reconstruction.shape[1]\n",
    "                observed_mask = observed_mask.unsqueeze(1).repeat((1, n_channels, 1))\n",
    "                masked_loss = observed_mask * recon_loss\n",
    "                loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n",
    "\n",
    "                if not np.isnan(float(loss)):\n",
    "                    loss.backward()\n",
    "                \n",
    "                logger.log({\n",
    "                     'step_loss_train': loss.item(),\n",
    "                     'lr': optimizer.param_groups[0]['lr']})\n",
    "                \n",
    "                nn.utils.clip_grad_norm_(model.parameters(), args.max_norm)\n",
    "                    \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                tr_loss += loss.detach().cpu().numpy()\n",
    "\n",
    "        logger.finish()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moment.models.timesnet import TimesNet\n",
    "from moment.models.gpt4ts import GPT4TS\n",
    "\n",
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 2\n",
    "\n",
    "config = Config(config_file_path=\"../../configs/anomaly_detection/gpt4ts_train.yaml\", \n",
    "                default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "args = parse_config(config)\n",
    "args.task_name = 'pre-training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT4TS(args)\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = args.train_batch_size\n",
    "train_dataloader = get_timeseries_dataloader(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_x in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(args, model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = args.train_batch_size\n",
    "args.data_split = 'test'\n",
    "test_dataloader = get_timeseries_dataloader(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trues = []\n",
    "preds = []\n",
    "masks = []\n",
    "for batch in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    timeseries = batch.timeseries.float().to(args.device)\n",
    "    input_mask = batch.input_mask.long().to(args.device)\n",
    "\n",
    "    # Training step\n",
    "    outputs = model.pretraining(x_enc=timeseries, input_mask=input_mask)\n",
    "\n",
    "    trues.append(timeseries.detach().cpu().numpy())\n",
    "    preds.append(outputs.reconstruction.detach().cpu().numpy())\n",
    "    masks.append(outputs.pretrain_mask.detach().cpu().numpy())\n",
    "\n",
    "trues = np.concatenate(trues, axis=0).squeeze()\n",
    "preds = np.concatenate(preds, axis=0).squeeze()\n",
    "masks = np.concatenate(masks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(trues)))\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "# Plot true and predicted values\n",
    "idx = np.random.choice(range(len(trues)))\n",
    "axs[0].set_title(f\"Sample {idx}\")\n",
    "axs[0].plot(trues[idx], c='k', \n",
    "        linewidth=1, label=\"True\")\n",
    "axs[0].plot(preds[idx], linewidth=0.75, c='darkred', label=\"Preds\")\n",
    "\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot masked locations\n",
    "axs[1].imshow(np.tile(masks[idx], reps=(8, 1)), cmap='binary')\n",
    "\n",
    "# Turn off x and y ticks\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../../configs/imputation/zero_shot.yaml'\n",
    "default_config_path = '../../configs/default.yaml'\n",
    "\n",
    "mask_ratios = [0.125, 0.25, 0.375, 0.5]\n",
    "\n",
    "def statistical_interpolation(y):\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    linear_y = y.interpolate(method='linear', axis=1).values\n",
    "    nearest_y = y.interpolate(method='nearest', axis=1).values\n",
    "    cubic_y = y.interpolate(method='cubic', axis=1).values\n",
    "\n",
    "    return linear_y, nearest_y, cubic_y\n",
    "\n",
    "def forward_backward_fill(y):\n",
    "        return pd.DataFrame(y).ffill(axis=1).bfill(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '/XXXX-14/project/public/XXXX-9/TimeseriesDatasets/forecasting/autoformer/ETTm1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_file_path=config_path, \n",
    "                default_config_file_path=default_config_path).parse()\n",
    "# config['device'] = gpu_id if torch.cuda.is_available() else 'cpu'\n",
    "args = parse_config(config)\n",
    "\n",
    "args.output_type = 'multivariate'\n",
    "args.seq_len = 512\n",
    "args.data_stride_len = 512\n",
    "args.batch_size = args.val_batch_size\n",
    "\n",
    "results = []\n",
    "\n",
    "args.full_file_path_and_name = dataset_name\n",
    "args.dataset_names = args.full_file_path_and_name\n",
    "args.data_split = 'test'\n",
    "test_dataloader = get_timeseries_dataloader(args=args)\n",
    "\n",
    "trues = []\n",
    "masks = {}        \n",
    "mask_generators = {}\n",
    "for mask_ratio in mask_ratios:\n",
    "    mask_generators[mask_ratio] = Masking(mask_ratio=mask_ratio) \n",
    "\n",
    "for batch_x in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    timeseries = batch_x.timeseries.float()\n",
    "    n_examples, n_channels, _ = timeseries.shape\n",
    "    timeseries = timeseries.reshape((-1, 1, args.seq_len))\n",
    "    \n",
    "    input_mask = batch_x.input_mask.long()\n",
    "    input_mask = input_mask.repeat_interleave(n_channels, axis=0)\n",
    "    trues.append(timeseries.squeeze().numpy())\n",
    "\n",
    "    for mask_ratio, mask_generator in mask_generators.items():\n",
    "        if mask_ratio not in masks:\n",
    "            masks[mask_ratio] = []\n",
    "        m = mask_generator.generate_mask(\n",
    "                x=timeseries, input_mask=input_mask)\n",
    "        masks[mask_ratio].append(m)\n",
    "    \n",
    "trues = np.concatenate(trues, axis=0)\n",
    "\n",
    "for mask_ratio in mask_ratios:\n",
    "    masks[mask_ratio] = np.concatenate(masks[mask_ratio], axis=0)\n",
    "\n",
    "for mask_ratio in tqdm(mask_ratios, total=len(mask_ratios)):\n",
    "    preds = trues.copy()\n",
    "    mask = masks[mask_ratio]\n",
    "    preds[mask == 0] = torch.nan\n",
    "    \n",
    "    preds_fbfill = forward_backward_fill(preds.copy())\n",
    "    preds_linear, preds_nearest, preds_cubic = statistical_interpolation(preds.copy())\n",
    "\n",
    "    metrics_fbfill = get_forecasting_metrics(\n",
    "        y=trues[mask==0], y_hat=preds_fbfill[mask==0], reduction='mean')\n",
    "    metrics_linear = get_forecasting_metrics(\n",
    "        y=trues[mask==0], y_hat=preds_linear[mask==0], reduction='mean')\n",
    "    metrics_nearest = get_forecasting_metrics(\n",
    "        y=trues[mask==0], y_hat=preds_nearest[mask==0], reduction='mean')\n",
    "    metrics_cubic = get_forecasting_metrics(\n",
    "        y=trues[mask==0], y_hat=preds_cubic[mask==0], reduction='mean')\n",
    "    \n",
    "    results.append([dataset_name.split('/')[-1][:-4], mask_ratio, \n",
    "                    metrics_fbfill.mse, metrics_fbfill.mae, \n",
    "                    metrics_linear.mse, metrics_linear.mae,\n",
    "                    metrics_nearest.mse, metrics_nearest.mae,\n",
    "                    metrics_cubic.mse, metrics_cubic.mae])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(trues)))\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "# Plot true and predicted values\n",
    "idx = np.random.choice(range(len(trues)))\n",
    "axs[0].set_title(f\"Sample {idx}\")\n",
    "axs[0].plot(trues[idx], c='k', \n",
    "        linewidth=1, label=\"True\")\n",
    "axs[0].plot(preds[idx], linewidth=0.75, c='darkred', label=\"Preds\")\n",
    "axs[0].plot(preds_linear[idx], linewidth=0.75, c='darkblue', label=\"Preds (L)\")\n",
    "axs[0].plot(preds_cubic[idx], linewidth=0.75, c='darkgreen', label=\"Preds (C)\")\n",
    "axs[0].plot(preds_nearest[idx], linewidth=0.75, c='pink', label=\"Preds (N)\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot masked locations\n",
    "axs[1].imshow(np.tile(mask[0.125][np.newaxis, idx], reps=(8, 1)), cmap='binary')\n",
    "\n",
    "# Turn off x and y ticks\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(args):\n",
    "    args.dataset_names = args.full_file_path_and_name\n",
    "    args.data_split = 'train'\n",
    "    train_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'test'\n",
    "    test_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'val'\n",
    "    val_dataloader = get_timeseries_dataloader(args=args)\n",
    "    return train_dataloader, test_dataloader, val_dataloader\n",
    "\n",
    "def load_pretrained_moment(args,\n",
    "                         pretraining_task_name: str = \"pre-training\"):\n",
    "    args.task_name = pretraining_task_name\n",
    "        \n",
    "    checkpoint = BaseModel.load_pretrained_weights(\n",
    "        run_name=args.pretraining_run_name, \n",
    "        opt_steps=args.pretraining_opt_steps)\n",
    "    \n",
    "    pretrained_model = MOMENTNT(configs=args)\n",
    "    pretrained_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    \n",
    "    return pretrained_model\n",
    "\n",
    "def repeated_fill(timeseries, mask, limit_area=None, limit=None):\n",
    "    # NOTE: This will only work for univariate time-series\n",
    "    # Set indices in timeseries where mask = 1 to NaN\n",
    "    timeseries = timeseries.squeeze()\n",
    "    timeseries[mask == 0] = torch.nan\n",
    "\n",
    "    timeseries = pd.DataFrame(\n",
    "        timeseries.detach().cpu().numpy()).ffill(\n",
    "            axis=1, limit=limit).bfill(axis=1, limit=limit).values\n",
    "    timeseries = torch.tensor(timeseries)\n",
    "    return timeseries.unsqueeze(1)\n",
    "\n",
    "def statistical_interpolation(y):\n",
    "    y = pd.DataFrame(y)\n",
    "    \n",
    "    linear_y = y.interpolate(method='linear', axis=1).values\n",
    "    nearest_y = y.interpolate(method='nearest', axis=1).values\n",
    "    cubic_y = y.interpolate(method='cubic', axis=1).values\n",
    "\n",
    "    return linear_y, nearest_y, cubic_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 1\n",
    "\n",
    "config = Config(config_file_path=\"../../configs/imputation/zero_shot.yaml\", \n",
    "                default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "args = parse_config(config)\n",
    "\n",
    "args.full_file_path_and_name = '/XXXX-14/project/public/XXXX-9/TimeseriesDatasets/forecasting/autoformer/ETTh1.csv'\n",
    "args.output_type = 'multivariate'\n",
    "args.batch_size = 256\n",
    "args.seq_len = 512\n",
    "\n",
    "model = load_pretrained_momentntntntntntnt(args)\n",
    "model.to(args.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting 1: Patches missing at random\n",
    "args.mask_ratio = 0.5\n",
    "args.data_stride_len = args.seq_len\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(args)\n",
    "mask_generator = Masking(mask_ratio=args.mask_ratio)\n",
    "\n",
    "trues = []\n",
    "preds = []\n",
    "input_masks = []\n",
    "masks = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        timeseries = batch_x.timeseries.float()\n",
    "        n_examples, n_channels, _ = timeseries.shape\n",
    "        timeseries = timeseries.reshape(\n",
    "            (n_examples*n_channels, 1, args.seq_len))\n",
    "        \n",
    "        trues.append(timeseries.detach().cpu().numpy().copy())\n",
    "        \n",
    "        input_mask = batch_x.input_mask\n",
    "        input_mask = input_mask.repeat_interleave(n_channels, dim=0)\n",
    "        input_masks.append(input_mask)\n",
    "        \n",
    "        mask = mask_generator.generate_mask(\n",
    "            x=timeseries, input_mask=input_mask)\n",
    "        masks.append(mask)\n",
    "        \n",
    "        # Move to device\n",
    "        timeseries = timeseries.to(args.device)\n",
    "        input_mask = input_mask.to(args.device)\n",
    "        mask = mask.to(args.device) \n",
    "        \n",
    "        outputs = model.reconstruct(\n",
    "            x_enc=timeseries, \n",
    "            input_mask=input_mask, \n",
    "            mask=mask)\n",
    "\n",
    "        preds.append(outputs.reconstruction.detach().cpu().numpy())\n",
    "        \n",
    "    trues = np.concatenate(trues, axis=0).squeeze()\n",
    "    preds = np.concatenate(preds, axis=0).squeeze()\n",
    "    input_masks = np.concatenate(input_masks, axis=0).squeeze()\n",
    "    masks = np.concatenate(masks, axis=0).squeeze()\n",
    "\n",
    "statistical_preds = trues.copy()\n",
    "statistical_preds[masks == 0] = torch.nan\n",
    "\n",
    "preds_linear, preds_nearest, preds_cubic = statistical_interpolation(statistical_preds.copy())\n",
    "\n",
    "# Careful -- Measure reconstruction of the masked patches\n",
    "moment_metrics = get_forecasting_metrics(\n",
    "    y=trues[masks == 0], y_hat=preds[masks == 0], reduction='mean')\n",
    "print('   MOMENTNT:', momentntnt_metrics)\n",
    "linear_metrics = get_forecasting_metrics(\n",
    "    y=trues[masks == 0], y_hat=preds_linear[masks == 0], reduction='mean')\n",
    "print(' Linear:', linear_metrics)\n",
    "nearest_metrics = get_forecasting_metrics(\n",
    "    y=trues[masks == 0], y_hat=preds_nearest[masks == 0], reduction='mean')\n",
    "print('Nearest:', nearest_metrics)\n",
    "cubic_metrics = get_forecasting_metrics(\n",
    "    y=trues[masks == 0], y_hat=preds_cubic[masks == 0], reduction='mean')\n",
    "print('  Cubic:', cubic_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(trues)))\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "# Plot true and predicted values\n",
    "idx = np.random.choice(range(len(trues)))\n",
    "axs[0].set_title(f\"Sample {idx}\")\n",
    "axs[0].plot(trues[idx], c='k', \n",
    "        linewidth=1, label=\"True\")\n",
    "axs[0].plot(preds[idx], linewidth=0.75, c='darkred', label=\"Preds\")\n",
    "axs[0].plot(preds_linear[idx], linewidth=0.75, c='darkblue', label=\"Preds (L)\")\n",
    "axs[0].plot(preds_cubic[idx], linewidth=0.75, c='darkgreen', label=\"Preds (C)\")\n",
    "axs[0].plot(preds_nearest[idx], linewidth=0.75, c='pink', label=\"Preds (N)\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot masked locations\n",
    "axs[1].imshow(np.tile(masks[np.newaxis, idx], reps=(8, 1)), cmap='binary')\n",
    "\n",
    "# Turn off x and y ticks\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trues = []\n",
    "# preds_with_attention = []\n",
    "# preds_without_attention = []\n",
    "# preds_with_repeated_fill = []\n",
    "# input_masks = []\n",
    "# masks = []\n",
    "\n",
    "# missing_mode = 'timesteps_missing_at_random' # 'patches_missing_at_random' 'timesteps_missing_at_random'\n",
    "# with torch.no_grad():\n",
    "#     for batch_x in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "#         timeseries = batch_x.timeseries.float()\n",
    "#         n_examples, n_channels, _ = timeseries.shape\n",
    "#         timeseries = timeseries.reshape(\n",
    "#             (n_examples*n_channels, 1, args.seq_len))\n",
    "        \n",
    "#         trues.append(timeseries.detach().cpu().numpy().copy())\n",
    "        \n",
    "#         input_mask = batch_x.input_mask\n",
    "#         input_mask = input_mask.repeat_interleave(n_channels, dim=0)\n",
    "#         input_masks.append(input_mask)\n",
    "        \n",
    "#         if missing_mode == 'timesteps_missing_at_random':\n",
    "#             mask = torch.rand_like(input_mask)\n",
    "            \n",
    "#             mask[mask <= args.mask_ratio] = 0 # masked\n",
    "#             mask[mask > args.mask_ratio] = 1  # oberseved\n",
    "#             masks.append(mask.detach().cpu().numpy())\n",
    "\n",
    "#             timeseries = repeated_fill(timeseries, mask, limit_area=None, limit=1)\n",
    "\n",
    "#             preds_with_repeated_fill.append(\n",
    "#                 timeseries.detach().cpu().numpy())\n",
    "\n",
    "#             mask = torch.isnan(timeseries).long().squeeze().to(args.device)\n",
    "#             torch.nan_to_num(timeseries, nan=0, out=timeseries) \n",
    "            \n",
    "#         elif missing_mode == 'patches_missing_at_random':\n",
    "#             mask = mask_generator.generate_mask(\n",
    "#                 x=timeseries, input_mask=input_mask)\n",
    "#             masks.append(mask)\n",
    "        \n",
    "#         # Move to device\n",
    "#         timeseries = timeseries.to(args.device)\n",
    "#         input_mask = input_mask.to(args.device)\n",
    "#         mask = mask.to(args.device) \n",
    "        \n",
    "#         outputs_with_attention = model.reconstruct(\n",
    "#             x_enc=timeseries, \n",
    "#             input_mask=input_mask, \n",
    "#             mask=mask)\n",
    "\n",
    "#         # Turn off attention to masked inputs\n",
    "#         input_mask = input_mask*mask\n",
    "\n",
    "#         outputs_without_attention = model.reconstruct(\n",
    "#             x_enc=timeseries, \n",
    "#             input_mask=input_mask)\n",
    "        \n",
    "#         preds_with_attention.append(\n",
    "#             outputs_with_attention.reconstruction.detach().cpu().numpy())\n",
    "#         preds_without_attention.append(\n",
    "#             outputs_without_attention.reconstruction.detach().cpu().numpy())\n",
    "        \n",
    "#     trues = np.concatenate(trues, axis=0).squeeze()\n",
    "#     preds_with_attention = np.concatenate(preds_with_attention, axis=0).squeeze()\n",
    "#     preds_without_attention = np.concatenate(preds_without_attention, axis=0).squeeze()\n",
    "#     input_masks = np.concatenate(input_masks, axis=0).squeeze()\n",
    "#     masks = np.concatenate(masks, axis=0).squeeze()\n",
    "    \n",
    "#     if missing_mode == 'timesteps_missing_at_random':\n",
    "#         preds_with_repeated_fill = np.concatenate(preds_with_repeated_fill, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trues = []\n",
    "# preds = []\n",
    "# preds_with_repeated_fill = []\n",
    "# input_masks = []\n",
    "# masks = []\n",
    "\n",
    "# missing_mode = 'timesteps_missing_at_random' # 'patches_missing_at_random' 'timesteps_missing_at_random'\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_x in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "#         timeseries = batch_x.timeseries.float()\n",
    "#         n_examples, n_channels, _ = timeseries.shape\n",
    "#         timeseries = timeseries.reshape(\n",
    "#             (n_examples*n_channels, 1, args.seq_len))\n",
    "        \n",
    "#         trues.append(timeseries.detach().cpu().numpy().copy())\n",
    "        \n",
    "#         input_mask = batch_x.input_mask\n",
    "#         input_mask = input_mask.repeat_interleave(n_channels, dim=0)\n",
    "#         input_masks.append(input_mask)\n",
    "        \n",
    "#         if missing_mode == 'timesteps_missing_at_random':\n",
    "#             mask = torch.rand_like(input_mask)\n",
    "            \n",
    "#             mask[mask <= args.mask_ratio] = 0 # masked\n",
    "#             mask[mask > args.mask_ratio] = 1  # oberseved\n",
    "#             masks.append(mask.detach().cpu().numpy())\n",
    "\n",
    "#             pred_repeated_fill = repeated_fill(timeseries, mask, limit_area=None, limit=None)\n",
    "#             timeseries = repeated_fill(timeseries, mask, limit_area=None, limit=1)\n",
    "\n",
    "#             preds_with_repeated_fill.append(pred_repeated_fill.detach().cpu().numpy())\n",
    "\n",
    "#             mask = torch.isnan(timeseries).long().squeeze().to(args.device)\n",
    "#             timeseries = torch.nan_to_num(timeseries, nan=0) \n",
    "            \n",
    "#         elif missing_mode == 'patches_missing_at_random':\n",
    "#             mask = mask_generator.generate_mask(\n",
    "#                 x=timeseries, input_mask=input_mask)\n",
    "#             masks.append(mask)\n",
    "        \n",
    "#         # Move to device\n",
    "#         timeseries = timeseries.to(args.device)\n",
    "#         input_mask = input_mask.to(args.device)\n",
    "#         mask = mask.to(args.device) \n",
    "        \n",
    "#         outputs = model.reconstruct(\n",
    "#             x_enc=timeseries, \n",
    "#             input_mask=input_mask, \n",
    "#             mask=mask)\n",
    "\n",
    "#         preds.append(outputs.reconstruction.detach().cpu().numpy())\n",
    "        \n",
    "#     trues = np.concatenate(trues, axis=0).squeeze()\n",
    "#     preds = np.concatenate(preds, axis=0).squeeze()\n",
    "#     input_masks = np.concatenate(input_masks, axis=0).squeeze()\n",
    "#     masks = np.concatenate(masks, axis=0).squeeze()\n",
    "    \n",
    "#     if missing_mode == 'timesteps_missing_at_random':\n",
    "#         preds_with_repeated_fill = np.concatenate(preds_with_repeated_fill, axis=0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(trues)))\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "# Plot true and predicted values\n",
    "idx = np.random.choice(range(len(trues)))\n",
    "axs[0].set_title(f\"Sample {idx}\")\n",
    "axs[0].plot(trues[idx], c='k', \n",
    "        linewidth=1, label=\"True\")\n",
    "axs[0].plot(preds[idx], linewidth=0.75, c='darkblue', label=\"Preds\")\n",
    "axs[0].plot(preds_with_repeated_fill[idx],\n",
    "        linewidth=0.75, c='darkred', label=\"Pred (repeated fill)\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot masked locations\n",
    "axs[1].imshow(np.tile(masks[np.newaxis, idx], reps=(8, 1)), cmap='binary')\n",
    "\n",
    "# Turn off x and y ticks\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(trues)))\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "\n",
    "# Plot true and predicted values\n",
    "idx = np.random.choice(range(len(trues)))\n",
    "axs[0].set_title(f\"Sample {idx}\")\n",
    "axs[0].plot(trues[idx], c='k', \n",
    "        linewidth=1, label=\"True\")\n",
    "axs[0].plot(preds_without_attention[idx], \n",
    "        linewidth=0.75, c='darkblue', label=\"Pred (w/o attention)\")\n",
    "axs[0].plot(preds_with_attention[idx], \n",
    "        linewidth=0.75, c='darkgreen', label=\"Pred (w/ attention\")\n",
    "# axs[0].plot(preds_with_repeated_fill[idx],\n",
    "#         linewidth=0.75, c='darkred', label=\"Pred (repeated fill)\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot masked locations\n",
    "axs[1].imshow(np.tile(masks[np.newaxis, idx], reps=(8, 1)), cmap='binary')\n",
    "\n",
    "# Turn off x and y ticks\n",
    "axs[1].set_xticks([])\n",
    "axs[1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
