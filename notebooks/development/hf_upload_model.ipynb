{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from argparse import Namespace\n",
    "\n",
    "from moment.utils.config import Config\n",
    "from moment.utils.utils import parse_config\n",
    "from moment.models.base import BaseModel\n",
    "from moment.models.moment import MOMENTPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pipeline_from_checkpoint(args: Namespace) -> MOMENTPipeline:\n",
    "    initial_args = deepcopy(args)\n",
    "    checkpoint_args = deepcopy(args)\n",
    "    model = MOMENTPipeline(initial_args)\n",
    "    checkpoint = BaseModel.load_pretrained_weights(\n",
    "        run_name=checkpoint_args.pretraining_run_name, \n",
    "        opt_steps=args.opt_steps\n",
    "    )\n",
    "    pretrained_model = MOMENTPipeline(checkpoint_args)\n",
    "    pretrained_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    # copy weights from pretrained model\n",
    "    do_not_copy_head = True\n",
    "    for ((name_p, param_p), (name_f, param_f)) in\\\n",
    "        zip(pretrained_model.named_parameters(), model.named_parameters()):\n",
    "        if (name_p == name_f) and (param_p.shape == param_f.shape):\n",
    "            if do_not_copy_head and name_p.startswith(\"head\"):\n",
    "                continue\n",
    "            else:\n",
    "                param_f.data = param_p.data\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"../../configs/model_hub/model_hub.yaml\"\n",
    "config = Config(\n",
    "    config_file_path=CONFIG_PATH,\n",
    "    default_config_file_path=CONFIG_PATH\n",
    ").parse()\n",
    "\n",
    "args = parse_config(config)\n",
    "args.device = \"cpu\"\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [\n",
    "    [\"MOMENT-large\", \"google/flan-t5-large\", \"fearless-planet-52-large\", 55000],\n",
    "]\n",
    "for name, encoder_id, checkpoint, steps in checkpoints:\n",
    "    # load checkpoint\n",
    "    args.transformer_backbone = encoder_id\n",
    "    args.pretraining_run_name = checkpoint\n",
    "    args.opt_steps = steps\n",
    "    args.model_kwargs = {} # placeholder for model kwargs\n",
    "    model = load_pipeline_from_checkpoint(args)\n",
    "    # clean up temp args\n",
    "    delattr(args, \"pretraining_run_name\") \n",
    "    delattr(args, \"opt_steps\")\n",
    "    # save model \n",
    "    config = vars(args)\n",
    "    model.save_pretrained(\n",
    "        f\"KonradSzafer/{name}\",\n",
    "        config=config,\n",
    "        push_to_hub=True,\n",
    "        private=True,\n",
    "    )\n",
    "    # check loading from hub\n",
    "    model = MOMENTPipeline.from_pretrained(\n",
    "        f\"KonradSzafer/{name}\",\n",
    "        model_kwargs={\n",
    "            \"task_name\": \"classification\",\n",
    "            \"n_channels\": 1,\n",
    "            \"num_class\": 2,\n",
    "        },\n",
    "    )\n",
    "    model.init()\n",
    "    print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
