{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from moment.utils.masking import Masking\n",
    "from moment.models.layers.revin import RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4])\n",
      "tensor([[0.7891, 0.5462, 0.3527, 0.4715],\n",
      "        [0.1525, 0.5782, 0.2720, 0.0549],\n",
      "        [0.2056, 0.4058, 0.1622, 0.1487],\n",
      "        [0.0691, 0.4874, 0.7084, 0.6822],\n",
      "        [0.8322, 0.3362, 0.0359, 0.9756],\n",
      "        [0.6620, 0.0850, 0.5008, 0.2533],\n",
      "        [0.3823, 0.8053, 0.0732, 0.1288],\n",
      "        [0.6464, 0.1721, 0.9925, 0.7255],\n",
      "        [0.3247, 0.0348, 0.9719, 0.6063],\n",
      "        [0.7039, 0.7127, 0.8540, 0.9093],\n",
      "        [0.0681, 0.9114, 0.6846, 0.2366],\n",
      "        [0.3610, 0.8556, 0.5669, 0.2921],\n",
      "        [0.9284, 0.3298, 0.6816, 0.4342],\n",
      "        [0.0929, 0.8676, 0.3866, 0.3630],\n",
      "        [0.8581, 0.6999, 0.6013, 0.2328],\n",
      "        [0.7122, 0.2464, 0.4994, 0.4607]])\n",
      "torch.Size([16, 4, 3])\n",
      "tensor([[[0.7891, 0.7891, 0.7891],\n",
      "         [0.5462, 0.5462, 0.5462],\n",
      "         [0.3527, 0.3527, 0.3527],\n",
      "         [0.4715, 0.4715, 0.4715]],\n",
      "\n",
      "        [[0.1525, 0.1525, 0.1525],\n",
      "         [0.5782, 0.5782, 0.5782],\n",
      "         [0.2720, 0.2720, 0.2720],\n",
      "         [0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "        [[0.2056, 0.2056, 0.2056],\n",
      "         [0.4058, 0.4058, 0.4058],\n",
      "         [0.1622, 0.1622, 0.1622],\n",
      "         [0.1487, 0.1487, 0.1487]],\n",
      "\n",
      "        [[0.0691, 0.0691, 0.0691],\n",
      "         [0.4874, 0.4874, 0.4874],\n",
      "         [0.7084, 0.7084, 0.7084],\n",
      "         [0.6822, 0.6822, 0.6822]],\n",
      "\n",
      "        [[0.8322, 0.8322, 0.8322],\n",
      "         [0.3362, 0.3362, 0.3362],\n",
      "         [0.0359, 0.0359, 0.0359],\n",
      "         [0.9756, 0.9756, 0.9756]],\n",
      "\n",
      "        [[0.6620, 0.6620, 0.6620],\n",
      "         [0.0850, 0.0850, 0.0850],\n",
      "         [0.5008, 0.5008, 0.5008],\n",
      "         [0.2533, 0.2533, 0.2533]],\n",
      "\n",
      "        [[0.3823, 0.3823, 0.3823],\n",
      "         [0.8053, 0.8053, 0.8053],\n",
      "         [0.0732, 0.0732, 0.0732],\n",
      "         [0.1288, 0.1288, 0.1288]],\n",
      "\n",
      "        [[0.6464, 0.6464, 0.6464],\n",
      "         [0.1721, 0.1721, 0.1721],\n",
      "         [0.9925, 0.9925, 0.9925],\n",
      "         [0.7255, 0.7255, 0.7255]],\n",
      "\n",
      "        [[0.3247, 0.3247, 0.3247],\n",
      "         [0.0348, 0.0348, 0.0348],\n",
      "         [0.9719, 0.9719, 0.9719],\n",
      "         [0.6063, 0.6063, 0.6063]],\n",
      "\n",
      "        [[0.7039, 0.7039, 0.7039],\n",
      "         [0.7127, 0.7127, 0.7127],\n",
      "         [0.8540, 0.8540, 0.8540],\n",
      "         [0.9093, 0.9093, 0.9093]],\n",
      "\n",
      "        [[0.0681, 0.0681, 0.0681],\n",
      "         [0.9114, 0.9114, 0.9114],\n",
      "         [0.6846, 0.6846, 0.6846],\n",
      "         [0.2366, 0.2366, 0.2366]],\n",
      "\n",
      "        [[0.3610, 0.3610, 0.3610],\n",
      "         [0.8556, 0.8556, 0.8556],\n",
      "         [0.5669, 0.5669, 0.5669],\n",
      "         [0.2921, 0.2921, 0.2921]],\n",
      "\n",
      "        [[0.9284, 0.9284, 0.9284],\n",
      "         [0.3298, 0.3298, 0.3298],\n",
      "         [0.6816, 0.6816, 0.6816],\n",
      "         [0.4342, 0.4342, 0.4342]],\n",
      "\n",
      "        [[0.0929, 0.0929, 0.0929],\n",
      "         [0.8676, 0.8676, 0.8676],\n",
      "         [0.3866, 0.3866, 0.3866],\n",
      "         [0.3630, 0.3630, 0.3630]],\n",
      "\n",
      "        [[0.8581, 0.8581, 0.8581],\n",
      "         [0.6999, 0.6999, 0.6999],\n",
      "         [0.6013, 0.6013, 0.6013],\n",
      "         [0.2328, 0.2328, 0.2328]],\n",
      "\n",
      "        [[0.7122, 0.7122, 0.7122],\n",
      "         [0.2464, 0.2464, 0.2464],\n",
      "         [0.4994, 0.4994, 0.4994],\n",
      "         [0.4607, 0.4607, 0.4607]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "n_patches = 4\n",
    "d_model = 3\n",
    "\n",
    "input_mask_patch_view = torch.rand((batch_size, n_patches))\n",
    "print(input_mask_patch_view.shape)\n",
    "print(input_mask_patch_view)\n",
    "\n",
    "expanded_mask = input_mask_patch_view.unsqueeze(-1).repeat(1, 1, d_model)\n",
    "print(expanded_mask.shape)\n",
    "print(expanded_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "seq_len = 8\n",
    "patch_len = 4\n",
    "n_channels = 2\n",
    "\n",
    "x_enc = torch.rand((batch_size, n_channels, seq_len))\n",
    "input_mask = torch.ones((batch_size, seq_len))\n",
    "mask_obj = Masking(mask_ratio=0.3, patch_len=patch_len, stride=patch_len)\n",
    "generated_mask = mask_obj.generate_mask(x_enc, input_mask=input_mask)\n",
    "print(generated_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64])\n"
     ]
    }
   ],
   "source": [
    "generated_mask_in_patch_view = Masking.convert_seq_to_patch_view(generated_mask)\n",
    "print(generated_mask_in_patch_view.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "generated_mask_in_seq_view = Masking.convert_patch_to_seq_view(generated_mask_in_patch_view)\n",
    "print(generated_mask_in_seq_view.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(generated_mask == generated_mask_in_seq_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_enc.shape: torch.Size([16, 1, 512])\n",
      "generated_mask.shape: torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_len = 512\n",
    "patch_len = 8\n",
    "n_channels = 1\n",
    "\n",
    "input_mask = torch.ones((batch_size, seq_len)) \n",
    "x_enc = torch.rand((batch_size, n_channels, seq_len))\n",
    "print(f\"x_enc.shape: {x_enc.shape}\")\n",
    "mask_obj = Masking(mask_ratio=0.3, patch_len=patch_len, stride=patch_len)\n",
    "generated_mask = mask_obj.generate_mask(x_enc, input_mask=input_mask)\n",
    "print(f\"generated_mask.shape: {generated_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moment.utils.data import nanvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Masked) Before reversible instance normalization: torch.Size([16, 1, 512]) \n",
      " tensor([0.5089, 0.5052, 0.5021, 0.5068, 0.4967, 0.5139, 0.4883, 0.5045, 0.5111,\n",
      "        0.5041, 0.5069, 0.5228, 0.5326, 0.5072, 0.4681, 0.4822]) \n",
      " tensor([0.0818, 0.0828, 0.0767, 0.0804, 0.0785, 0.0832, 0.0773, 0.0774, 0.0782,\n",
      "        0.0805, 0.0851, 0.0795, 0.0876, 0.0806, 0.0739, 0.0895])\n",
      "(Masked) After reversible instance normalization: torch.Size([16, 1, 512]) \n",
      " tensor([-5.1657e-08,  8.2122e-08, -1.3245e-07,  0.0000e+00, -8.8745e-08,\n",
      "        -6.6227e-08,  1.8279e-07,  1.1921e-08, -1.9868e-08, -3.9736e-09,\n",
      "        -6.6227e-08,  7.1526e-08, -7.5499e-08,  1.3245e-09,  8.7420e-08,\n",
      "         1.6689e-07]) \n",
      " tensor([0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999])\n",
      "(Masked) After reversible instance denormalization: torch.Size([16, 1, 512]) \n",
      " \n",
      " tensor([0.5089, 0.5052, 0.5021, 0.5068, 0.4967, 0.5139, 0.4883, 0.5045, 0.5111,\n",
      "        0.5041, 0.5069, 0.5228, 0.5326, 0.5072, 0.4681, 0.4822]) \n",
      " tensor([0.0818, 0.0828, 0.0767, 0.0804, 0.0785, 0.0832, 0.0773, 0.0774, 0.0782,\n",
      "        0.0805, 0.0851, 0.0795, 0.0876, 0.0806, 0.0739, 0.0895])\n"
     ]
    }
   ],
   "source": [
    "revin_obj = RevIN(num_features=n_channels, affine=False)\n",
    "x_enc_norm = revin_obj(x_enc, mask=generated_mask, mode=\"norm\")\n",
    "masked_x_enc = torch.where(generated_mask.unsqueeze(1).bool(), x_enc, torch.nan)\n",
    "\n",
    "# print(\"Before reversible instance normalization:\", x_enc.shape, \n",
    "#       '\\n', x_enc.squeeze().mean(axis=-1), '\\n', x_enc.squeeze().var(axis=-1))\n",
    "print(\"(Masked) Before reversible instance normalization:\", masked_x_enc.shape, \n",
    "      '\\n', masked_x_enc.squeeze().nanmean(axis=-1), '\\n', nanvar(masked_x_enc.squeeze(), dim=-1))\n",
    "\n",
    "masked_x_enc_norm = torch.where(generated_mask.unsqueeze(1).bool(), x_enc_norm, torch.nan)\n",
    "# print(\"After reversible instance normalization:\", x_enc_norm.shape, \n",
    "#       '\\n', x_enc_norm.squeeze().nanmean(dim=-1), '\\n', x_enc_norm.squeeze().var(axis=-1))\n",
    "print(\"(Masked) After reversible instance normalization:\", masked_x_enc_norm.shape, \n",
    "      '\\n', masked_x_enc_norm.squeeze().nanmean(axis=-1), '\\n', nanvar(masked_x_enc_norm.squeeze(), dim=-1))\n",
    "\n",
    "x_enc_denorm = revin_obj(x_enc_norm, mode=\"denorm\")\n",
    "masked_x_enc_denorm = torch.where(generated_mask.unsqueeze(1).bool(), x_enc_denorm, torch.nan)\n",
    "# print(\"After reversible instance denormalization:\", x_enc_denorm.shape, '\\n', \n",
    "#       x_enc_denorm.squeeze().mean(axis=-1), '\\n', x_enc_denorm.squeeze().var(axis=-1))\n",
    "print(\"(Masked) After reversible instance denormalization:\", x_enc_denorm.shape, '\\n', \n",
    "      '\\n', masked_x_enc_denorm.squeeze().nanmean(axis=-1), '\\n', nanvar(masked_x_enc_denorm.squeeze(), dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reversible instance normalization: torch.Size([8, 3, 512]) tensor(0.5017) tensor(0.0830)\n",
      "After reversible instance normalization: torch.Size([8, 3, 512]) tensor(0.0029, grad_fn=<MeanBackward0>) tensor(0.9950, grad_fn=<VarBackward0>)\n",
      "After reversible instance denormalization: torch.Size([8, 3, 512]) tensor(0.5017, grad_fn=<MeanBackward0>) tensor(0.0830, grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "revin_obj = RevIN(num_features=n_channels, affine=True)\n",
    "x_enc_norm = revin_obj(x_enc, mask=generated_mask, mode=\"norm\")\n",
    "\n",
    "print(\"Before reversible instance normalization:\", x_enc.shape, x_enc.mean(), x_enc.var())\n",
    "print(\"After reversible instance normalization:\", x_enc_norm.shape, x_enc_norm.mean(), x_enc_norm.var())\n",
    "\n",
    "x_enc_denorm = revin_obj(x_enc_norm, mode=\"denorm\")\n",
    "print(\"After reversible instance denormalization:\", x_enc_denorm.shape, x_enc_denorm.mean(), x_enc_denorm.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "         1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "         0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "         1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "         0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "         1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "         1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "         1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0],\n",
       "        [1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Masking.convert_seq_to_patch_view(generated_mask, patch_len=patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "mask_embedding = nn.Parameter(torch.zeros(768))\n",
    "nn.init.trunc_normal_(mask_embedding, mean=0.0, std=.02)\n",
    "value_embedding = nn.Linear(patch_len, 768, bias=True)\n",
    "\n",
    "n_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.6563e-03,  1.1400e-02,  3.8069e-02, -2.7084e-02,  6.1327e-03,\n",
      "        -3.8223e-03,  9.5821e-03,  9.1625e-03, -7.8339e-03, -2.7275e-02,\n",
      "        -1.9771e-04,  1.7950e-02,  1.8530e-02,  1.4511e-03,  9.0782e-03,\n",
      "        -9.0193e-03,  8.3833e-03,  5.5514e-03, -1.7480e-02,  5.3386e-03,\n",
      "        -1.1893e-02,  3.7317e-03, -1.3266e-02,  8.8647e-03,  3.4053e-02,\n",
      "         3.5585e-02, -7.9008e-03,  4.0723e-02, -2.1418e-03, -1.1216e-03,\n",
      "        -1.6082e-02, -3.5233e-02,  8.3909e-03, -1.7249e-02,  5.7902e-03,\n",
      "         1.4509e-02, -9.2847e-03, -1.3128e-02,  1.4970e-02, -8.8669e-03,\n",
      "        -9.5377e-03,  1.1817e-02,  2.5525e-02,  5.4501e-03, -4.0365e-03,\n",
      "         1.9814e-03, -9.6465e-03,  1.7635e-02, -6.6043e-03, -1.3949e-04,\n",
      "        -5.4365e-03,  5.9173e-03, -2.0668e-02,  2.6240e-03, -6.0574e-03,\n",
      "        -3.7557e-02, -2.5533e-02, -7.9768e-03, -7.7971e-03, -1.0771e-03,\n",
      "        -8.2750e-03,  1.0797e-02,  1.7825e-02, -8.5885e-04, -4.8601e-03,\n",
      "        -1.0844e-03, -3.4335e-02, -3.8358e-03, -1.4413e-02,  1.7631e-02,\n",
      "         1.8537e-03,  3.9834e-02, -4.7474e-03, -2.9833e-02, -1.1623e-02,\n",
      "        -2.5446e-03, -9.3575e-03,  6.9903e-03, -2.4267e-02,  1.4767e-03,\n",
      "         1.7681e-02,  7.3923e-03, -1.2458e-02,  5.7335e-03, -2.2346e-02,\n",
      "         7.1511e-03,  1.7648e-02, -4.3418e-03, -2.3873e-02, -1.6817e-02,\n",
      "        -5.5195e-04, -1.6010e-02, -3.8255e-02, -8.0107e-03, -5.1079e-03,\n",
      "         4.3933e-02, -3.0513e-02,  1.9246e-03, -8.7357e-04,  1.1721e-02,\n",
      "        -8.9065e-03,  8.5149e-03, -1.6959e-04, -2.4754e-02,  3.4600e-02,\n",
      "        -7.4977e-03, -8.2257e-03,  2.0161e-02, -2.7626e-02, -1.6601e-02,\n",
      "        -5.1028e-03, -1.9006e-02, -1.2121e-02,  5.9972e-04, -2.0627e-02,\n",
      "        -3.6976e-03, -4.1593e-02,  2.4407e-02, -4.7870e-02,  4.8613e-02,\n",
      "         2.0112e-02,  3.8444e-03,  1.7508e-02,  1.2023e-02, -1.0002e-03,\n",
      "         5.9247e-03, -2.0052e-02, -1.6941e-02,  3.0730e-02, -4.8240e-03,\n",
      "        -7.7108e-03, -1.7690e-02,  4.2687e-02,  1.8918e-03,  1.4693e-02,\n",
      "        -1.0147e-02,  3.0110e-02,  1.7108e-02, -1.2980e-02, -2.1871e-02,\n",
      "        -3.7717e-03,  3.7879e-02, -1.4552e-02, -4.4484e-03,  1.1469e-03,\n",
      "        -1.0763e-02,  1.5151e-02, -2.0811e-03, -5.7480e-03, -1.6336e-02,\n",
      "         3.4936e-02, -1.5818e-02,  1.4138e-02, -3.3863e-03,  3.8085e-02,\n",
      "        -1.3316e-02,  8.0311e-03,  6.2697e-04,  4.0837e-02, -1.0031e-02,\n",
      "        -2.1288e-02,  2.4917e-02, -5.4547e-02,  6.6146e-03,  2.5621e-02,\n",
      "        -5.0031e-04, -1.1504e-02, -1.1725e-02,  2.2408e-02,  9.8155e-03,\n",
      "        -4.3268e-02,  6.9627e-03, -1.1249e-02,  9.5012e-03, -1.7550e-02,\n",
      "         2.3291e-02,  1.1853e-02,  1.1318e-02,  2.7510e-03, -9.7024e-03,\n",
      "        -2.3707e-02, -1.0605e-02,  1.0214e-04,  6.6748e-03, -8.2722e-03,\n",
      "        -2.6370e-03, -1.2367e-02,  1.1305e-02, -3.0194e-03, -2.0832e-02,\n",
      "        -3.8479e-02, -1.3746e-02,  2.2859e-03, -3.1238e-02,  1.1573e-02,\n",
      "        -9.3402e-03, -2.0793e-02,  5.0046e-02,  2.2439e-02,  4.1189e-02,\n",
      "         1.6938e-02,  2.9700e-02,  1.9082e-02, -9.3237e-03, -5.5742e-03,\n",
      "        -2.0876e-03, -3.3963e-02, -3.0911e-03, -1.1853e-02, -8.9506e-04,\n",
      "         7.4087e-03,  3.4004e-02,  2.4626e-02, -1.5882e-02, -5.5575e-02,\n",
      "         9.7413e-03, -3.8873e-02,  4.0138e-02, -2.6105e-02, -1.7085e-02,\n",
      "         8.3997e-03,  2.0939e-03, -3.4890e-02,  1.3264e-02,  7.6245e-03,\n",
      "        -1.9469e-02,  2.7133e-02,  6.0244e-03,  1.5691e-02,  8.4922e-04,\n",
      "         1.0749e-02, -3.1498e-02,  3.0116e-02, -7.4835e-03, -3.8290e-03,\n",
      "        -1.7280e-02, -1.2049e-02,  9.2913e-03, -3.2950e-02,  1.1194e-02,\n",
      "        -2.5223e-02,  2.9128e-02, -1.7950e-02,  1.4315e-02, -3.3441e-02,\n",
      "        -6.5872e-02,  3.3659e-02, -2.1881e-02, -1.8135e-02,  1.8917e-03,\n",
      "        -3.3333e-03,  1.7357e-02, -3.0847e-02,  1.9338e-02,  5.6676e-03,\n",
      "         5.3265e-03,  1.1125e-02,  3.7312e-02,  3.0588e-02, -1.4254e-02,\n",
      "         1.5486e-02,  2.5696e-02, -1.8590e-02,  5.2770e-02,  2.1505e-03,\n",
      "         2.0260e-02,  1.9696e-02,  1.4103e-02, -9.0456e-03,  1.8929e-02,\n",
      "         6.2348e-03,  1.9720e-02, -1.6136e-02, -7.4046e-04, -2.5873e-03,\n",
      "        -1.0742e-02,  8.9406e-03, -4.4458e-02,  1.0287e-02,  1.7169e-02,\n",
      "        -2.0491e-03, -2.8219e-04, -5.5801e-03, -3.6135e-04,  1.6685e-02,\n",
      "         9.6742e-03,  2.7693e-02,  1.0007e-02, -8.6200e-03, -2.1121e-02,\n",
      "        -1.1431e-02, -9.7952e-04,  5.6006e-03,  9.9613e-03, -3.4416e-02,\n",
      "        -6.9711e-03, -8.0398e-03, -6.5097e-03,  2.5535e-02,  2.8539e-02,\n",
      "         4.6777e-02,  2.7272e-02,  3.6274e-03,  2.5932e-03,  3.7399e-02,\n",
      "         3.5499e-02, -4.1010e-02,  1.7110e-02, -8.4723e-03,  6.8842e-03,\n",
      "        -1.6608e-02, -1.5587e-02, -1.4007e-03, -5.7415e-03,  7.0625e-03,\n",
      "         8.7521e-03, -3.2318e-03, -2.5980e-02, -1.8505e-02,  2.1030e-02,\n",
      "        -3.0951e-02,  3.6011e-03,  3.4556e-03, -1.3002e-02,  4.0626e-03,\n",
      "         2.0430e-02, -2.0434e-02,  1.3156e-02,  3.3172e-02, -2.0717e-02,\n",
      "         2.6103e-02, -2.2376e-03,  2.1730e-02,  4.4344e-03, -1.4601e-02,\n",
      "        -6.3558e-03, -2.0709e-02, -1.0784e-02, -5.7145e-03,  7.0436e-03,\n",
      "         2.9689e-02, -1.6174e-03, -3.5119e-02,  3.4532e-02,  2.3251e-02,\n",
      "        -7.2507e-03, -1.7552e-02,  2.4479e-02, -1.2012e-02,  2.0314e-02,\n",
      "        -1.6125e-02,  3.3451e-02, -1.8230e-02, -2.0129e-02, -2.2905e-02,\n",
      "        -3.9170e-03, -3.0766e-04,  1.1682e-03,  1.2391e-02,  3.1784e-02,\n",
      "        -5.5319e-03, -1.9795e-02, -1.3334e-02, -8.0454e-03, -6.4450e-03,\n",
      "         1.4845e-03,  8.2403e-03, -1.2676e-02,  3.6368e-02, -8.5830e-03,\n",
      "         1.2649e-02,  3.8464e-02, -3.0785e-02, -1.7813e-02,  2.6572e-02,\n",
      "        -2.8243e-04, -1.0295e-02,  2.2786e-02,  1.6797e-02,  5.6762e-03,\n",
      "        -2.1390e-02, -1.0617e-02,  2.1590e-02,  8.0773e-03,  1.7074e-02,\n",
      "        -1.9633e-03, -2.7807e-02,  6.9518e-03,  8.7724e-03, -2.6856e-02,\n",
      "         4.3075e-03,  5.3351e-04, -2.2741e-02,  1.9743e-02,  5.8461e-03,\n",
      "        -5.9317e-03, -3.6796e-02,  2.2966e-02,  1.7336e-02, -1.5518e-02,\n",
      "        -3.5508e-03, -1.3305e-02,  8.2478e-03, -1.7502e-02, -3.4356e-02,\n",
      "        -2.3981e-02,  1.4766e-02, -1.4304e-02, -1.0170e-02, -1.9965e-02,\n",
      "        -2.9784e-02, -4.0757e-03, -2.5704e-02,  7.2686e-03,  4.0753e-02,\n",
      "         5.2333e-03,  2.5405e-02,  1.7057e-04, -8.8756e-03,  3.7458e-02,\n",
      "         5.1296e-02,  1.8043e-02, -1.9949e-02,  3.0887e-03, -1.2658e-02,\n",
      "        -4.7910e-03, -1.5007e-02, -5.0549e-03, -1.2782e-02, -2.2811e-02,\n",
      "         1.7231e-03,  2.0538e-03,  4.6136e-03, -6.1933e-03,  2.9477e-02,\n",
      "        -1.1708e-03, -1.8757e-02, -9.3620e-03, -8.2562e-04, -9.7449e-03,\n",
      "        -1.7854e-02, -1.5109e-02,  3.4684e-04, -3.6108e-03, -5.8921e-03,\n",
      "         1.7659e-02, -3.9785e-03, -8.2978e-03,  3.6082e-03, -1.7373e-02,\n",
      "        -1.2934e-02, -2.0469e-03, -7.8239e-03,  8.5872e-03,  4.9712e-02,\n",
      "        -6.4044e-03, -4.3331e-03, -2.4120e-03, -1.7865e-02,  9.6835e-03,\n",
      "         1.0202e-02, -2.1922e-02,  1.1109e-02,  1.2388e-02,  1.0018e-02,\n",
      "        -1.2847e-02, -5.1030e-03, -8.1860e-03,  1.5638e-02, -7.8404e-03,\n",
      "        -3.2186e-02,  1.5958e-03, -1.1012e-02, -8.4951e-03,  1.8330e-02,\n",
      "        -9.3907e-03, -9.3898e-03, -2.7736e-03, -1.3036e-02,  8.1617e-03,\n",
      "         4.1761e-02,  2.4657e-02,  7.2570e-04,  2.1468e-02,  2.2002e-02,\n",
      "         4.4946e-02, -1.8999e-02,  7.7576e-03,  2.1096e-02,  2.2274e-02,\n",
      "         2.3493e-02,  1.8615e-02,  4.1002e-02,  3.8271e-02,  2.2021e-02,\n",
      "        -1.2397e-02, -1.6504e-02,  1.8822e-02, -2.0671e-02, -5.2683e-02,\n",
      "        -9.5592e-03,  1.6657e-02, -5.2847e-03,  4.1862e-03, -3.4096e-02,\n",
      "         1.5644e-02,  1.1043e-02, -6.2214e-04, -3.5939e-02, -2.7065e-02,\n",
      "        -1.5895e-02,  3.4475e-02, -4.3799e-02, -1.7052e-02,  5.8130e-03,\n",
      "        -5.6216e-03,  6.2322e-04,  4.6059e-02,  4.0323e-02,  4.6933e-03,\n",
      "        -8.5430e-03, -2.0675e-02,  2.3859e-03, -2.2390e-03,  8.3256e-04,\n",
      "         4.5505e-04,  1.3529e-02, -3.4257e-02, -3.0777e-04,  2.3505e-02,\n",
      "         1.4934e-02,  1.1670e-02,  4.5498e-02,  1.5222e-02,  1.2899e-02,\n",
      "        -2.2198e-02,  1.3988e-02,  2.8112e-03, -9.2174e-03,  3.7928e-03,\n",
      "        -3.2801e-02, -1.9994e-03, -1.6769e-02, -1.7234e-02,  3.2156e-03,\n",
      "         6.8235e-03, -1.7920e-02,  3.2813e-03, -7.7091e-05,  2.3676e-03,\n",
      "         8.7536e-03, -1.8740e-03, -8.9413e-03,  2.6147e-03, -3.3626e-02,\n",
      "         4.4477e-02,  1.9316e-02, -3.6393e-02,  6.9042e-03, -6.2393e-03,\n",
      "        -6.8153e-03,  1.8194e-02, -2.6963e-02, -8.2696e-03,  1.8060e-02,\n",
      "         3.3195e-03,  3.2947e-02,  1.5377e-02,  1.1283e-03,  4.2619e-03,\n",
      "        -2.8513e-02, -1.5602e-02,  1.9302e-02, -1.0177e-02,  5.7812e-03,\n",
      "         2.1615e-02,  2.2134e-03,  3.0786e-03,  1.1244e-02, -1.4301e-02,\n",
      "         8.3807e-03,  9.3930e-03, -1.5703e-02, -2.2533e-02,  1.9134e-02,\n",
      "         1.5430e-02,  2.1351e-03,  1.3325e-02, -1.2316e-02,  7.5258e-03,\n",
      "        -6.5088e-03,  1.6414e-02, -1.4735e-02,  7.0152e-03, -1.7136e-02,\n",
      "        -2.4932e-02, -3.0844e-03, -3.4235e-03,  5.7457e-03,  5.9865e-03,\n",
      "        -1.7382e-02,  3.8397e-02,  2.7057e-03, -4.8727e-02, -1.2214e-02,\n",
      "        -1.9626e-02, -9.2229e-03, -1.8260e-02,  1.4042e-03,  2.0038e-02,\n",
      "        -1.1014e-02, -1.5343e-02,  3.3302e-02, -1.0657e-02,  3.1680e-04,\n",
      "        -2.3139e-02,  1.2244e-02, -2.7067e-02,  3.9137e-03, -1.9878e-02,\n",
      "         1.0958e-02, -9.9440e-03, -5.5658e-04, -1.2823e-02,  2.7048e-02,\n",
      "         3.7771e-03,  1.6034e-02, -5.1354e-03,  5.6638e-03,  7.9024e-04,\n",
      "        -8.9085e-03,  1.5397e-02, -7.2071e-03,  5.9883e-03,  2.7850e-03,\n",
      "         4.0160e-02,  6.9876e-03,  1.0788e-02, -2.4363e-02, -1.6697e-02,\n",
      "        -5.2419e-02, -1.2936e-03,  1.1469e-02, -9.9476e-03, -7.5744e-03,\n",
      "         5.4925e-03, -3.0146e-02,  8.9601e-03,  6.7407e-03,  2.6529e-02,\n",
      "        -2.0184e-02,  1.5394e-02, -5.4039e-03,  2.5818e-02, -1.2119e-02,\n",
      "         8.9600e-03, -1.5201e-03, -2.4692e-02, -9.5399e-03, -6.0492e-03,\n",
      "        -2.3639e-02, -4.1891e-02, -2.2945e-02, -1.4364e-02,  3.6107e-03,\n",
      "        -1.8949e-02, -9.6761e-03,  4.5152e-03,  3.5750e-03,  5.1189e-03,\n",
      "         4.0278e-02,  1.2958e-02,  5.3016e-03,  1.7134e-02,  1.4584e-02,\n",
      "         4.3020e-03,  2.0812e-02, -3.2333e-03, -1.6447e-02, -2.2343e-02,\n",
      "         2.1004e-03, -9.3256e-03, -5.4420e-02,  4.2557e-03, -2.1220e-02,\n",
      "        -6.5758e-03, -5.9008e-03,  2.1696e-02, -3.8176e-02,  1.9392e-02,\n",
      "        -9.1755e-03, -1.7205e-02, -2.6400e-02,  2.0137e-02,  1.6290e-02,\n",
      "        -2.8290e-02,  1.5564e-02,  1.7031e-02, -2.1371e-03,  2.6317e-02,\n",
      "        -1.0686e-02,  8.6333e-03, -3.2402e-02,  8.5943e-03,  1.7047e-02,\n",
      "        -1.4979e-02,  3.8690e-02, -7.7514e-03, -2.2143e-02, -4.9583e-02,\n",
      "        -5.6702e-03, -1.4932e-02, -5.1370e-03, -2.4302e-02, -6.5759e-04,\n",
      "        -1.4159e-02, -2.8445e-02,  1.9026e-02, -1.8400e-02, -1.4083e-02,\n",
      "         5.5270e-02,  9.7203e-03,  7.7720e-03,  3.1320e-02, -6.7567e-03,\n",
      "        -3.4413e-02, -2.1747e-02, -6.6694e-03,  3.0910e-02,  1.8917e-02,\n",
      "         5.0047e-03,  3.5511e-03, -2.7249e-02, -8.0614e-03,  2.5206e-03,\n",
      "         6.3165e-03, -1.7793e-02,  2.1109e-02, -2.8196e-02, -3.4311e-03,\n",
      "         1.8083e-02,  2.8847e-02, -1.8186e-02,  1.7422e-02,  5.7289e-02,\n",
      "         1.8179e-02,  4.1265e-03, -7.5159e-03,  4.5493e-02,  2.1283e-02,\n",
      "        -2.4922e-02, -3.7074e-03,  4.6602e-02,  1.3790e-02,  2.1328e-02,\n",
      "        -2.7187e-02, -7.2643e-04,  1.6890e-02, -1.4712e-02, -8.2970e-03,\n",
      "        -6.1163e-03,  7.5984e-03,  8.7563e-03,  1.5092e-04,  1.3424e-02,\n",
      "         1.4595e-02,  1.0146e-02, -3.1505e-03], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(mask_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512])\n"
     ]
    }
   ],
   "source": [
    "print(generated_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((batch_size, n_channels, 64, patch_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "mask = Masking.convert_seq_to_patch_view(generated_mask, patch_len=patch_len).unsqueeze(-1)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 64, 768])\n"
     ]
    }
   ],
   "source": [
    "mask = mask.repeat_interleave(768, dim=-1).unsqueeze(1).repeat(1, n_channels, 1, 1)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.reshape((x.shape[0] * n_channels, x.shape[2], x.shape[3]))\n",
    "# mask = mask.reshape((mask.shape[0] * n_channels, mask.shape[2], mask.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "seq_len = 16\n",
    "patch_len = 4\n",
    "n_channels = 1\n",
    "\n",
    "x_enc = torch.rand((batch_size, n_channels, seq_len))\n",
    "\n",
    "mask_obj = Masking(mask_ratio=0.3, patch_len=patch_len, stride=patch_len)\n",
    "generated_mask = mask_obj.generate_mask(x_enc)\n",
    "generated_mask_1 = mask_obj.generate_mask(x_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_x = torch.where(generated_mask.bool(), x_enc, torch.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5564, 0.0124, 0.9068, 0.0675,    nan,    nan,    nan,    nan,\n",
       "          0.2088, 0.3609, 0.7477, 0.3044,    nan,    nan,    nan,    nan],\n",
       "         [0.5564, 0.0124, 0.9068, 0.0675, 0.1514, 0.8795, 0.4807, 0.9743,\n",
       "          0.2088, 0.3609, 0.7477, 0.3044,    nan,    nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "          0.2088, 0.3609, 0.7477, 0.3044, 0.7728, 0.5436, 0.1199, 0.0566],\n",
       "         [   nan,    nan,    nan,    nan, 0.1514, 0.8795, 0.4807, 0.9743,\n",
       "             nan,    nan,    nan,    nan, 0.7728, 0.5436, 0.1199, 0.0566],\n",
       "         [0.5564, 0.0124, 0.9068, 0.0675, 0.1514, 0.8795, 0.4807, 0.9743,\n",
       "          0.2088, 0.3609, 0.7477, 0.3044,    nan,    nan,    nan,    nan]],\n",
       "\n",
       "        [[0.2979, 0.9697, 0.1694, 0.4599,    nan,    nan,    nan,    nan,\n",
       "          0.6839, 0.0991, 0.4961, 0.0106,    nan,    nan,    nan,    nan],\n",
       "         [0.2979, 0.9697, 0.1694, 0.4599, 0.1915, 0.2373, 0.0655, 0.7039,\n",
       "          0.6839, 0.0991, 0.4961, 0.0106,    nan,    nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "          0.6839, 0.0991, 0.4961, 0.0106, 0.9825, 0.9424, 0.5077, 0.7341],\n",
       "         [   nan,    nan,    nan,    nan, 0.1915, 0.2373, 0.0655, 0.7039,\n",
       "             nan,    nan,    nan,    nan, 0.9825, 0.9424, 0.5077, 0.7341],\n",
       "         [0.2979, 0.9697, 0.1694, 0.4599, 0.1915, 0.2373, 0.0655, 0.7039,\n",
       "          0.6839, 0.0991, 0.4961, 0.0106,    nan,    nan,    nan,    nan]],\n",
       "\n",
       "        [[0.6913, 0.8528, 0.5055, 0.6832,    nan,    nan,    nan,    nan,\n",
       "          0.7720, 0.3303, 0.8618, 0.3293,    nan,    nan,    nan,    nan],\n",
       "         [0.6913, 0.8528, 0.5055, 0.6832, 0.1138, 0.1737, 0.3883, 0.2330,\n",
       "          0.7720, 0.3303, 0.8618, 0.3293,    nan,    nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "          0.7720, 0.3303, 0.8618, 0.3293, 0.9892, 0.2570, 0.7460, 0.3443],\n",
       "         [   nan,    nan,    nan,    nan, 0.1138, 0.1737, 0.3883, 0.2330,\n",
       "             nan,    nan,    nan,    nan, 0.9892, 0.2570, 0.7460, 0.3443],\n",
       "         [0.6913, 0.8528, 0.5055, 0.6832, 0.1138, 0.1737, 0.3883, 0.2330,\n",
       "          0.7720, 0.3303, 0.8618, 0.3293,    nan,    nan,    nan,    nan]],\n",
       "\n",
       "        [[0.2814, 0.4108, 0.1498, 0.3577,    nan,    nan,    nan,    nan,\n",
       "          0.1239, 0.1763, 0.6144, 0.1148,    nan,    nan,    nan,    nan],\n",
       "         [0.2814, 0.4108, 0.1498, 0.3577, 0.9775, 0.5708, 0.5053, 0.4100,\n",
       "          0.1239, 0.1763, 0.6144, 0.1148,    nan,    nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "          0.1239, 0.1763, 0.6144, 0.1148, 0.6121, 0.3413, 0.0312, 0.9940],\n",
       "         [   nan,    nan,    nan,    nan, 0.9775, 0.5708, 0.5053, 0.4100,\n",
       "             nan,    nan,    nan,    nan, 0.6121, 0.3413, 0.0312, 0.9940],\n",
       "         [0.2814, 0.4108, 0.1498, 0.3577, 0.9775, 0.5708, 0.5053, 0.4100,\n",
       "          0.1239, 0.1763, 0.6144, 0.1148,    nan,    nan,    nan,    nan]],\n",
       "\n",
       "        [[0.3595, 0.5909, 0.7239, 0.7772,    nan,    nan,    nan,    nan,\n",
       "          0.9577, 0.6266, 0.7928, 0.7263,    nan,    nan,    nan,    nan],\n",
       "         [0.3595, 0.5909, 0.7239, 0.7772, 0.7813, 0.5018, 0.7378, 0.4233,\n",
       "          0.9577, 0.6266, 0.7928, 0.7263,    nan,    nan,    nan,    nan],\n",
       "         [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "          0.9577, 0.6266, 0.7928, 0.7263, 0.1082, 0.0455, 0.9054, 0.5477],\n",
       "         [   nan,    nan,    nan,    nan, 0.7813, 0.5018, 0.7378, 0.4233,\n",
       "             nan,    nan,    nan,    nan, 0.1082, 0.0455, 0.9054, 0.5477],\n",
       "         [0.3595, 0.5909, 0.7239, 0.7772, 0.7813, 0.5018, 0.7378, 0.4233,\n",
       "          0.9577, 0.6266, 0.7928, 0.7263,    nan,    nan,    nan,    nan]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]]) \n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(generated_mask, f'\\n{generated_mask_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_mask*generated_mask_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 16]) torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "print(x_enc.shape, generated_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0125, 0.2545, 0.2849, 0.0521, 0.5358, 0.6295, 0.6922, 0.1970, 0.4741,\n",
       "        0.2726, 0.4006, 0.8102, 0.7616, 0.4026, 0.9062, 0.7949, 0.9387, 0.1628,\n",
       "        0.3855, 0.8334, 0.6171, 0.0557, 0.8788, 0.0384, 0.1543, 0.0154, 0.1122,\n",
       "        0.1321, 0.6690, 0.6656, 0.5286, 0.6932, 0.4928, 0.8596, 0.3379, 0.2115,\n",
       "        0.9073, 0.5408, 0.6029, 0.0463, 0.5339, 0.4061, 0.4120, 0.9525, 0.5427,\n",
       "        0.4730, 0.5600, 0.2020, 0.1492, 0.9209, 0.4773, 0.8560])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(input=x_enc, mask=generated_mask.unsqueeze(1).repeat((1,n_channels,1)).bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 16]) \n",
      "tensor([[[0.0125, 0.2545, 0.2849, 0.0521, 0.5358, 0.6295, 0.6922, 0.1970,\n",
      "          0.4741, 0.2726, 0.4006, 0.8102, 0.7616, 0.4026, 0.9062, 0.7949]],\n",
      "\n",
      "        [[0.9387, 0.1628, 0.3855, 0.8334, 0.6171, 0.0557, 0.8788, 0.0384,\n",
      "          0.1543, 0.0154, 0.1122, 0.1321, 0.6690, 0.6656, 0.5286, 0.6932]],\n",
      "\n",
      "        [[   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "             nan,    nan,    nan,    nan, 0.4928, 0.8596, 0.3379, 0.2115]],\n",
      "\n",
      "        [[0.9073, 0.5408, 0.6029, 0.0463,    nan,    nan,    nan,    nan,\n",
      "          0.5339, 0.4061, 0.4120, 0.9525,    nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.5427, 0.4730, 0.5600, 0.2020,    nan,    nan,    nan,    nan,\n",
      "             nan,    nan,    nan,    nan, 0.1492, 0.9209, 0.4773, 0.8560]]])\n"
     ]
    }
   ],
   "source": [
    "masked_tensor = torch.where(generated_mask.unsqueeze(1).repeat((1,n_channels,1)).bool(), x_enc, torch.nan)\n",
    "print(masked_tensor.shape, f'\\n{masked_tensor}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
