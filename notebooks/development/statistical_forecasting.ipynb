{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    AutoARIMA,\n",
    "    AutoETS,\n",
    "    AutoTheta, \n",
    "    SeasonalNaive,\n",
    "    Naive,\n",
    "    RandomWalkWithDrift\n",
    ")\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from moment.utils.forecasting_metrics import get_forecasting_metrics\n",
    "from moment.utils.config import Config\n",
    "from moment.utils.utils import parse_config\n",
    "from moment.data.dataloader import get_timeseries_dataloader\n",
    "from moment.data.forecasting_datasets import get_forecasting_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_forecasting_datasets = get_forecasting_datasets(collection=\"monash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloaders(args):\n",
    "    args.data_split = 'val'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    val_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'test'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    test_dataloader = get_timeseries_dataloader(args=args)\n",
    "    return val_dataloader, test_dataloader\n",
    "\n",
    "HORIZON_MAPPING = {'hourly': 48, 'daily': 14, 'weekly': 13, 'monthly': 18, 'quarterly': 8, 'yearly': 6, 'other': 8}\n",
    "SEASONAL_MAPPING = {'yearly': 1, 'quarterly': 4, 'monthly': 12, 'weekly': 1, 'daily': 1, 'hourly': 24, 'other': 1}\n",
    "FREQUENCY_MAPPING = {'yearly': 'Y', 'quarterly': 'Q', 'monthly': 'M', 'weekly': 'W', 'daily': 'D', 'hourly': 'h', 'other': 'Q'}\n",
    "\n",
    "def preprecess_dataset_for_statsforecast(dataset) -> pd.DataFrame:\n",
    "    histories = []\n",
    "    targets = []\n",
    "    timestamps_history = []\n",
    "    timestamps_target = []\n",
    "    unique_ids_history = []\n",
    "    unique_ids_target = []\n",
    "    forecast_horizon = dataset.forecast_horizon \n",
    "    \n",
    "    for i in trange(dataset.length_dataset):\n",
    "        metadata = dataset[i].metadata \n",
    "        history = dataset.data.iloc[i, :].series_value.to_numpy()\n",
    "        timestamps = np.arange(1, len(history)+1)\n",
    "        target = history[-forecast_horizon:]\n",
    "        history = history[:-forecast_horizon]\n",
    "        \n",
    "        histories.append(history)\n",
    "        targets.append(target)\n",
    "        timestamps_history.append(timestamps[:-forecast_horizon])\n",
    "        timestamps_target.append(timestamps[-forecast_horizon:])\n",
    "        unique_ids_history.append(len(history)*[metadata[\"series_name\"]])\n",
    "        unique_ids_target.append(len(target)*[metadata[\"series_name\"]])\n",
    "    \n",
    "    histories = np.concatenate(histories, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    timestamps_history = np.concatenate(timestamps_history, axis=0)\n",
    "    timestamps_target = np.concatenate(timestamps_target, axis=0)\n",
    "    unique_ids_history = np.concatenate(unique_ids_history, axis=0)\n",
    "    unique_ids_target = np.concatenate(unique_ids_target, axis=0)\n",
    "\n",
    "    history_df = pd.DataFrame({\n",
    "        \"unique_id\": unique_ids_history, \n",
    "        \"ds\": timestamps_history, \n",
    "        \"y\": histories})\n",
    "    target_df = pd.DataFrame({\n",
    "        \"unique_id\": unique_ids_target, \n",
    "        \"ds\": timestamps_target, \n",
    "        \"Target\": targets})\n",
    "    \n",
    "    return history_df, target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "FREQUENCIES = {\n",
    "    \"m3\": ['yearly', 'quarterly', 'monthly', 'other'],\n",
    "    \"m4\": ['yearly', 'quarterly', 'monthly', 'weekly', 'daily', 'hourly']\n",
    "}\n",
    "MODEL_NAMES = ['AutoARIMA', 'AutoETS', 'AutoTheta', 'SeasonalNaive', 'Naive', 'RWD']\n",
    "BASE_PATH = '/'.join(short_forecasting_datasets[0].split('/')[:-1])\n",
    "file_format = 'tsf'\n",
    "\n",
    "config = Config(config_file_path=\"../../configs/forecasting/zero_shot.yaml\", \n",
    "                default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "args = parse_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for dataset in [\"m3\", \"m4\"]:\n",
    "    for frequency in FREQUENCIES[dataset]:\n",
    "        print(f\"Dataset: {dataset}, Frequency: {frequency}\")\n",
    "        args.full_file_path_and_name = os.path.join(BASE_PATH, f\"{dataset}_{frequency}_dataset.{file_format}\")    \n",
    "        args.dataset_names = args.full_file_path_and_name\n",
    "        args.forecast_horizon = HORIZON_MAPPING[frequency]\n",
    "        args.season_length = SEASONAL_MAPPING[frequency]\n",
    "        args.frequency = FREQUENCY_MAPPING[frequency]\n",
    "\n",
    "        val_dataloader, test_dataloader = get_test_dataloaders(args)\n",
    "        print(f\"Forecast horizon: {test_dataloader.dataset.forecast_horizon}\")\n",
    "        print(f\"Length Test: {test_dataloader.dataset.length_dataset + val_dataloader.dataset.length_dataset}\")\n",
    "\n",
    "        val_history_df, val_target_df = preprecess_dataset_for_statsforecast(val_dataloader.dataset)\n",
    "        test_history_df, test_target_df = preprecess_dataset_for_statsforecast(test_dataloader.dataset)\n",
    "        history_df = pd.concat([val_history_df, test_history_df], axis=0)\n",
    "        target_df = pd.concat([val_target_df, test_target_df], axis=0)\n",
    "\n",
    "        assert test_dataloader.dataset.length_dataset + val_dataloader.dataset.length_dataset == len(history_df.unique_id.unique())\n",
    "\n",
    "        # print(f\"# of time-series: {len(history_df.unique_id.unique())}\")\n",
    "\n",
    "        models = [\n",
    "            AutoARIMA(season_length=args.season_length),\n",
    "            AutoETS(season_length=args.season_length),\n",
    "            AutoTheta(season_length=args.season_length),\n",
    "            SeasonalNaive(season_length=args.season_length),\n",
    "            Naive(),\n",
    "            RandomWalkWithDrift(),\n",
    "        ]\n",
    "\n",
    "        sf = StatsForecast(models=models, freq=args.frequency, n_jobs=args.n_jobs)\n",
    "        sf.fit(history_df)\n",
    "\n",
    "        forecast_df = sf.predict(h=args.forecast_horizon)\n",
    "        forecast_df.reset_index(inplace=True)\n",
    "\n",
    "        # Add the true valus to the dataframe\n",
    "        forecast_df = forecast_df.merge(target_df, on=[\"unique_id\", \"ds\"])\n",
    "\n",
    "        assert test_dataloader.dataset.length_dataset + val_dataloader.dataset.length_dataset == len(forecast_df.unique_id.unique())\n",
    "\n",
    "        for model_name in MODEL_NAMES:\n",
    "            y_hat = forecast_df.loc[:, model_name]\n",
    "            y = forecast_df.loc[:, \"Target\"]\n",
    "            forecasting_metrics = get_forecasting_metrics(y=y, y_hat=y_hat, reduction=\"mean\")\n",
    "            results.append([\n",
    "                dataset, \n",
    "                frequency,\n",
    "                model_name,\n",
    "                forecasting_metrics.mape, \n",
    "                forecasting_metrics.smape])\n",
    "\n",
    "results = pd.DataFrame(results, columns=[\"Dataset\", \"Frequency\", \"Model\", \"MAPE\", \"sMAPE\"])\n",
    "results.to_csv(f\"../../assets/results/zero_shot/statistical_forecasting_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
