{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from moment.utils.config import Config\n",
    "from moment.utils.utils import parse_config\n",
    "from moment.utils.forecasting_metrics import get_forecasting_metrics\n",
    "from moment.data.dataloader import get_timeseries_dataloader\n",
    "from moment.data.forecasting_datasets import get_forecasting_datasets, ShortForecastingDataset\n",
    "from moment.models.base import BaseModel\n",
    "from moment.models.moment import MOMENT\n",
    "from moment.models.nbeats import NBEATS\n",
    "from moment.models.nhits import NHITS\n",
    "from moment.models.timesnet import TimesNet\n",
    "from moment.models.gpt4ts import GPT4TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(args):\n",
    "    args.dataset_names = args.full_file_path_and_name\n",
    "    args.data_split = 'train'\n",
    "    args.batch_size = args.train_batch_size\n",
    "    train_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'test'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    test_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'val'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    val_dataloader = get_timeseries_dataloader(args=args)\n",
    "    return train_dataloader, test_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_forecasting_datasets(collection=\"autoformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 4\n",
    "\n",
    "config = Config(config_file_path=\"../../configs/forecasting/linear_probing.yaml\", \n",
    "                default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = parse_config(config)\n",
    "args.full_file_path_and_name = '/XXXX-14/project/public/XXXX-9/TimeseriesDatasets/forecasting/autoformer/ETTh1.csv'\n",
    "args.dataset_names = args.full_file_path_and_name\n",
    "args.task_name = \"long-horizon-forecasting\"\n",
    "# args.forecast_horizon = 0 # Must be set to 0 for reconstruction / imputation / anomaly detection\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(args)\n",
    "print(f\"Forecast horizon: {train_dataloader.dataset.forecast_horizon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_forecasting_datasets = get_forecasting_datasets(collection=\"monash\")\n",
    "fred_forecasting_datasets = get_forecasting_datasets(collection=\"fred/preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"M3 datasets:\")\n",
    "m_datasets_base_path = '/'.join(short_forecasting_datasets[0].split('/')[:-1])\n",
    "print(f\"--- M3 & M4 datasets (base path): {m_datasets_base_path}\")\n",
    "print(\"--- M3 splits:\", [i.split('/')[-1] for i in short_forecasting_datasets if \"m3\" in i])\n",
    "print(\"--- M4 splits:\", [i.split('/')[-1] for i in short_forecasting_datasets if \"m4\" in i])\n",
    "\n",
    "print(\"Fred datasets:\")\n",
    "fred_datasets_base_path = '/'.join(fred_forecasting_datasets[0].split('/')[:-1])\n",
    "print(f\"--- FRED datasets (base path): {fred_datasets_base_path}\")\n",
    "print('--- Splits:', [i.split('/')[-1] for i in fred_forecasting_datasets if \"fred\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(args):\n",
    "    args.dataset_names = args.full_file_path_and_name\n",
    "    args.data_split = 'train'\n",
    "    args.batch_size = args.train_batch_size\n",
    "    train_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'test'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    test_dataloader = get_timeseries_dataloader(args=args)\n",
    "    args.data_split = 'val'\n",
    "    args.batch_size = args.val_batch_size\n",
    "    val_dataloader = get_timeseries_dataloader(args=args)\n",
    "    return train_dataloader, test_dataloader, val_dataloader\n",
    "\n",
    "def load_pretrained_moment(args, \n",
    "                         pretraining_task_name: str = \"pre-training\",\n",
    "                         do_not_copy_head: bool = True):\n",
    "        \n",
    "        model = MOMENT(configs=args)\n",
    "        pretraining_args = deepcopy(args)\n",
    "        pretraining_args.task_name = pretraining_task_name\n",
    "            \n",
    "        checkpoint = BaseModel.load_pretrained_weights(\n",
    "            run_name=pretraining_args.pretraining_run_name, \n",
    "            opt_steps=pretraining_args.pretraining_opt_steps)\n",
    "        \n",
    "        pretrained_model = MOMENT(configs=pretraining_args)\n",
    "        pretrained_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        # Copy pre-trained parameters to fine-tuned model\n",
    "        for ((name_p, param_p), (name_f, param_f)) in\\\n",
    "            zip(pretrained_model.named_parameters(), model.named_parameters()):\n",
    "            if (name_p == name_f) and (param_p.shape == param_f.shape):\n",
    "                if do_not_copy_head and name_p.startswith(\"head\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    param_f.data = param_p.data\n",
    "        \n",
    "        if args.finetuning_mode == 'linear-probing':\n",
    "            for name, param in model.named_parameters():\n",
    "                if not name.startswith(\"head\"):\n",
    "                    param.requires_grad = False\n",
    "        \n",
    "        print(\"====== Frozen parameter status ======\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(\"Not frozen:\", name)\n",
    "            else:\n",
    "                print(\"Frozen:\", name)\n",
    "        print(\"=====================================\")\n",
    "\n",
    "        return model\n",
    "\n",
    "HORIZON_MAPPING = {\n",
    "    'hourly': 48,\n",
    "    'daily': 14,\n",
    "    'weekly': 13,\n",
    "    'monthly': 18,\n",
    "    'quarterly': 8,\n",
    "    'yearly': 6\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 1\n",
    "FREQUENCY = \"yearly\" # \"monthly\" | \"quarterly\" | \"yearly\" | \"daily\" | \"hourly\" | \"weekly\" | \"other\"\n",
    "DATASET = \"m3\" # \"m3\" | \"m4\" | \"fred\"\n",
    "BASE_PATH = m_datasets_base_path if DATASET in ['m3', 'm4'] else fred_datasets_base_path\n",
    "\n",
    "# config_file_path = \"../../configs/forecasting/linear_probing_short_horizon.yaml\"\n",
    "# config_file_path = \"../../configs/forecasting/nbeats.yaml\"\n",
    "config_file_path = \"../../configs/forecasting/nhits.yaml\"\n",
    "# config_file_path = \"../../configs/forecasting/timesnet.yaml\"\n",
    "# config_file_path = \"../../configs/forecasting/gpt4ts.yaml\"\n",
    "\n",
    "config = Config(config_file_path=config_file_path, \n",
    "                default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = parse_config(config)\n",
    "\n",
    "file_format = 'tsf' if DATASET in ['m3', 'm4'] else 'npy'\n",
    "args.full_file_path_and_name = os.path.join(BASE_PATH, f\"{DATASET}_{FREQUENCY}_dataset.{file_format}\")    \n",
    "args.dataset_names = args.full_file_path_and_name\n",
    "args.forecast_horizon = HORIZON_MAPPING[FREQUENCY]\n",
    "args.max_epoch = 5\n",
    "args.train_batch_size = 64\n",
    "args.val_batch_size = 64\n",
    "args.use_amp = False\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(args)\n",
    "print(f\"Forecast horizon: {train_dataloader.dataset.forecast_horizon}\")\n",
    "print(f\"Lengths: Train: {train_dataloader.dataset.length_dataset} | Test: {test_dataloader.dataset.length_dataset} | Val: {val_dataloader.dataset.length_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPT4TS(args)\n",
    "# model = TimesNet(args)\n",
    "# model = NBEATS(args)\n",
    "model = NHITS(args)\n",
    "# model = load_pretrained_moment(args)\n",
    "model.to(args.device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "print(f\"Traininable parameters: {trainable_params}\")\n",
    "print(f\"Percentage of trainable parameters: {trainable_params / total_params * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from moment.common import PATHS\n",
    "from moment.utils.utils import dtype_map\n",
    "from moment.utils.forecasting_metrics import sMAPELoss\n",
    "\n",
    "\n",
    "def train(args, model, train_dataloader):\n",
    "    # Setup logger\n",
    "    logger = wandb.init(\n",
    "            project=\"Time-series Foundation Model\",\n",
    "            dir=PATHS.WANDB_DIR)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=args.init_lr,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.use_amp)\n",
    "    # criterion = nn.MSELoss(reduction='mean')\n",
    "    criterion = sMAPELoss(reduction='mean')\n",
    "\n",
    "    opt_steps = 0\n",
    "    cur_epoch = 0\n",
    "    \n",
    "    while cur_epoch < args.max_epoch: # Epoch based learning only\n",
    "        model.train()\n",
    "        \n",
    "        for batch_x in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            timeseries = batch_x.timeseries.float().to(args.device)\n",
    "            input_mask = batch_x.input_mask.long().to(args.device)\n",
    "            forecast = batch_x.forecast.float().to(args.device)\n",
    "\n",
    "            # _scaler = torch.max(timeseries, dim=-1, keepdim=True)[0]\n",
    "            # timeseries = timeseries / _scaler\n",
    "            \n",
    "            with torch.autocast(device_type='cuda', \n",
    "                                dtype=dtype_map(args.torch_dtype), \n",
    "                                enabled=args.use_amp):\n",
    "                # outputs = model.long_forecast(\n",
    "                #     x_enc=timeseries, input_mask=input_mask, mask=None)\n",
    "                outputs = model(\n",
    "                    x_enc=timeseries, input_mask=input_mask, mask=None)\n",
    "\n",
    "                # outputs.forecast = outputs.forecast * _scaler\n",
    "            \n",
    "            loss = criterion(outputs.forecast, forecast)\n",
    "            logger.log({\"step_train_loss\": loss.item()})   \n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), args.max_norm)\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            opt_steps = opt_steps + 1\n",
    "\n",
    "        cur_epoch = cur_epoch + 1\n",
    "    \n",
    "    logger.finish()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args, model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(args, model, data_loader, return_preds):\n",
    "    trues, preds, histories, losses = [], [], [], []\n",
    "\n",
    "    # criterion = nn.MSELoss(reduction='mean')\n",
    "    criterion = sMAPELoss(reduction='mean')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x in tqdm(data_loader, total=len(data_loader)):\n",
    "            timeseries = batch_x.timeseries.float().to(args.device)\n",
    "            input_mask = batch_x.input_mask.long().to(args.device)\n",
    "            forecast = batch_x.forecast.float().to(args.device)\n",
    "            forecast_horizon = forecast.shape[-1]\n",
    "\n",
    "            scaler = torch.max(timeseries, dim=-1, keepdim=True)[0]\n",
    "            timeseries = timeseries / scaler\n",
    "\n",
    "            with torch.autocast(device_type='cuda', \n",
    "                                dtype=dtype_map(args.torch_dtype), \n",
    "                                enabled=args.use_amp):\n",
    "                # outputs = model.long_forecast(x_enc=timeseries, \n",
    "                #                         input_mask=input_mask, \n",
    "                #                         mask=None)\n",
    "                outputs = model(x_enc=timeseries, \n",
    "                                        input_mask=input_mask, \n",
    "                                        mask=None)\n",
    "                outputs.forecast = outputs.forecast * scaler\n",
    "\n",
    "            if outputs.forecast.shape != forecast:\n",
    "                outputs.forecast = outputs.forecast[:, :forecast_horizon]\n",
    "                \n",
    "            loss = criterion(outputs.forecast, forecast)                \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if return_preds:\n",
    "                trues.append(forecast.detach().cpu().numpy())\n",
    "                preds.append(outputs.forecast.detach().cpu().numpy())\n",
    "                histories.append(timeseries.detach().cpu().numpy())\n",
    "    \n",
    "    losses = np.array(losses)\n",
    "    average_loss = np.average(losses)\n",
    "    model.train()\n",
    "\n",
    "    if return_preds:\n",
    "        trues = np.concatenate(trues, axis=0)\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        histories = np.concatenate(histories, axis=0)\n",
    "        return average_loss, losses, (trues, preds, histories)\n",
    "    else:\n",
    "        return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, (trues_val, preds_val, _) = validation(args, model, val_dataloader, return_preds=True)\n",
    "_, _, (trues_test, preds_test, _) = validation(args, model, test_dataloader, return_preds=True)\n",
    "trues = np.concatenate([trues_val, trues_test], axis=0)\n",
    "preds = np.concatenate([preds_val, preds_test], axis=0)\n",
    "\n",
    "get_forecasting_metrics(y=trues, y_hat=preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
