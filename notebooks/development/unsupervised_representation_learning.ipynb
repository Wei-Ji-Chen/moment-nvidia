{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "from moment.utils.config import Config\n",
    "from moment.utils.utils import parse_config\n",
    "from moment.data.dataloader import get_timeseries_dataloader\n",
    "from moment.data.classification_datasets import get_classification_datasets\n",
    "from moment.models.base import BaseModel\n",
    "from moment.models.moment import MOMENT\n",
    "from moment.models.statistical_classifiers import fit_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs\n",
    "- [x] Download evaluation results from TS2Vec\n",
    "- [] Handle multi-variate time-series\n",
    "- [] Fine-tune models on classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_labels(model : torch.nn.Module, \n",
    "                              dataloader : torch.utils.data.DataLoader,\n",
    "                              device : torch.device, \n",
    "                              dimension_reduction_method : str = 'tsne', \n",
    "                              n_components : Optional[int] = 320,\n",
    "                              enable_embedding_pbar : bool = False):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x in tqdm(dataloader, total=len(dataloader), disable=(not enable_embedding_pbar)):\n",
    "            timeseries = batch_x.timeseries.float().to(device)\n",
    "            input_mask = batch_x.input_mask.long().to(device)\n",
    "\n",
    "            outputs = model.embed(x_enc=timeseries, input_mask=input_mask, reduction='mean')\n",
    "            \n",
    "            embeddings_ = outputs.embeddings.detach().cpu().numpy()\n",
    "            embeddings.append(embeddings_)\n",
    "            labels.append(batch_x.labels)\n",
    "\n",
    "        embeddings = np.concatenate(embeddings, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0).squeeze()\n",
    "\n",
    "    if dimension_reduction_method == 'tsne':\n",
    "        embeddings = TSNE(n_components=n_components, n_jobs=5).fit_transform(embeddings)\n",
    "    elif dimension_reduction_method == 'pca':\n",
    "        embeddings = PCA(n_components=n_components).fit_transform(embeddings)\n",
    "    elif dimension_reduction_method == 'none':\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Dimension reduction method {dimension_reduction_method} not supported.\")\n",
    "    \n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_datasets = get_classification_datasets(collection=\"UCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\n",
    "    \"task_name\": \"classification\",\n",
    "    \"full_file_path_and_name\": '/XXXX-14/project/public/XXXX-9/TimeseriesDatasets/classification/UCR/FaceFour/Wine_TEST.ts',\n",
    "    \"batch_size\": 512,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 5,\n",
    "    \"pin_memory\": True,\n",
    "    \"seq_len\" : 512,\n",
    "    \"data_split\": 'train', # We are just doing this for the train part!!!\n",
    "    \"scale\" : True,\n",
    "    \"train_ratio\" : 0.6,\n",
    "    \"val_ratio\" : 0.1,\n",
    "    \"test_ratio\" : 0.3,\n",
    "    \"random_seed\" : 13,\n",
    "    \"upsampling_pad_direction\" : \"backward\",\n",
    "    \"upsampling_type\" : \"interpolate\", # pad by default\n",
    "    \"downsampling_type\" : \"interpolate\",\n",
    "    \"pad_mode\" : \"constant\",\n",
    "    \"pad_constant_values\" : 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationDataset(dataset_name=FaceFour,n_timeseries=20,dataset_size=20,length_of_each_timeseries=350,n_channels=1,seq_len=512,data_split=train,scale=True,task_name=classification,train_ratio=0.6,val_ratio=0.1,test_ratio=0.3,output_type=univariate)\n",
      "ClassificationDataset(dataset_name=FaceFour,n_timeseries=4,dataset_size=4,length_of_each_timeseries=350,n_channels=1,seq_len=512,data_split=val,scale=True,task_name=classification,train_ratio=0.6,val_ratio=0.1,test_ratio=0.3,output_type=univariate)\n",
      "ClassificationDataset(dataset_name=FaceFour,n_timeseries=88,dataset_size=88,length_of_each_timeseries=350,n_channels=1,seq_len=512,data_split=test,scale=True,task_name=classification,train_ratio=0.6,val_ratio=0.1,test_ratio=0.3,output_type=univariate)\n"
     ]
    }
   ],
   "source": [
    "args = parse_config(arguments)\n",
    "args.dataset_names = args.full_file_path_and_name\n",
    "\n",
    "args.data_split = 'train'\n",
    "train_dataloader = get_timeseries_dataloader(args=args)\n",
    "args.data_split = 'test'\n",
    "test_dataloader = get_timeseries_dataloader(args=args)\n",
    "args.data_split = 'val'\n",
    "val_dataloader = get_timeseries_dataloader(args=args)\n",
    "\n",
    "print(train_dataloader.dataset)\n",
    "print(val_dataloader.dataset)\n",
    "print(test_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "DEFAULT_CONFIG_PATH = \"../../configs/default.yaml\"\n",
    "GPU_ID = 7\n",
    "run_name = \"fast-pyramid-63\" # \"avid-moon-55\" \"proud-dust-41\" \"curious-blaze-53\" \"laced-firebrand-51\" \"prime-music-50\" \"fast-pyramid-63\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = BaseModel.load_pretrained_weights(run_name=run_name, \n",
    "                                               opt_steps=20000)\n",
    "\n",
    "config = Config(config_file_path=DEFAULT_CONFIG_PATH, default_config_file_path=DEFAULT_CONFIG_PATH).parse()\n",
    "config['device'] = GPU_ID if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args = parse_config(config)\n",
    "model = MOMENT(configs=args)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moment.models.statistical_classifiers import fit_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings, train_labels = get_embeddings_and_labels(model=model, \n",
    "                                    dataloader=train_dataloader,\n",
    "                                    device=torch.device(GPU_ID), \n",
    "                                    dimension_reduction_method='none', \n",
    "                                    n_components=None)\n",
    "val_embeddings, val_labels = get_embeddings_and_labels(model=model, \n",
    "                                    dataloader=val_dataloader,\n",
    "                                    device=torch.device(GPU_ID), \n",
    "                                    dimension_reduction_method='none', \n",
    "                                    n_components=None)\n",
    "test_embeddings, test_labels = get_embeddings_and_labels(model=model, \n",
    "                                    dataloader=test_dataloader,\n",
    "                                    device=torch.device(GPU_ID), \n",
    "                                    dimension_reduction_method='none', \n",
    "                                    n_components=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.concatenate([train_embeddings, val_embeddings], axis=0)\n",
    "train_labels = np.concatenate([train_labels, val_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 768) (23,)\n",
      "(88, 768) (88,)\n"
     ]
    }
   ],
   "source": [
    "print(train_embeddings.shape, train_labels.shape)\n",
    "print(test_embeddings.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "results_path = f\"/home/extra_scratch/XXXX-2/moment_results/unsupervised_representation_learning/fast-pyramid-63/results_AllGestureWiimoteZ_TEST.pkl\"\n",
    "with open(results_path, \"rb\") as f:\n",
    "    results_object = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 768) (300,)\n",
      "(700, 768) (700,)\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = results_object.train_embeddings\n",
    "train_labels = results_object.train_labels\n",
    "test_embeddings = results_object.test_embeddings\n",
    "test_labels = results_object.test_labels\n",
    "print(train_embeddings.shape, train_labels.shape)\n",
    "print(test_embeddings.shape, test_labels.shape)\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# train_labels = label_encoder.fit_transform(train_labels)    \n",
    "# test_labels = label_encoder.transform(test_labels)\n",
    "# print(f\"Number of classes:\", len(np.unique(train_labels)), label_encoder.classes_)\n",
    "\n",
    "# Standard normalize the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False, with_std=False)\n",
    "X_train = scaler.fit_transform(train_embeddings)\n",
    "X_test = scaler.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape\n",
    "embedding_size = 320\n",
    "n_components = min(n_samples, n_features, embedding_size)\n",
    "pca = PCA(n_components=n_components).fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, coef0=0, max_iter=10000000)\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.5757142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = fit_svm(features=X_train, y=train_labels)\n",
    "# classifier = SVC(C=1e8, gamma='scale')\n",
    "# classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=13)\n",
    "classifier.fit(X_train, train_labels)\n",
    "print(classifier)\n",
    "print(\"Train accuracy:\", classifier.score(X_train, train_labels))\n",
    "print(\"Test accuracy:\", classifier.score(X_test, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14 13]\n",
      " [15 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.52      0.50        27\n",
      "           1       0.48      0.44      0.46        27\n",
      "\n",
      "    accuracy                           0.48        54\n",
      "   macro avg       0.48      0.48      0.48        54\n",
      "weighted avg       0.48      0.48      0.48        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_true = test_labels, y_pred = y_preds))\n",
    "print(classification_report(y_true = test_labels, y_pred = y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>numTrainCases</th>\n",
       "      <th>numTestCases</th>\n",
       "      <th>seriesLength</th>\n",
       "      <th>numClasses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACSF1</td>\n",
       "      <td>100</td>\n",
       "      <td>1001460</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adiac</td>\n",
       "      <td>390</td>\n",
       "      <td>391176</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AllGestureWiimoteX</td>\n",
       "      <td>300</td>\n",
       "      <td>700500</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AllGestureWiimoteY</td>\n",
       "      <td>300</td>\n",
       "      <td>700500</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AllGestureWiimoteZ</td>\n",
       "      <td>300</td>\n",
       "      <td>700500</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              problem  numTrainCases  numTestCases  seriesLength  numClasses\n",
       "0               ACSF1            100       1001460            10         NaN\n",
       "1               Adiac            390        391176            37         NaN\n",
       "2  AllGestureWiimoteX            300        700500            10         NaN\n",
       "3  AllGestureWiimoteY            300        700500            10         NaN\n",
       "4  AllGestureWiimoteZ            300        700500            10         NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "summary = pd.read_csv(\"../../assets/data/summaryUnivariate.csv\")\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(summary[\"seriesLength\"] <= 512).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
